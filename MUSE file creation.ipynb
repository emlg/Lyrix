{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import json\n",
    "import random\n",
    "import csv\n",
    "from collections import Counter\n",
    "#MUSE Part\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import norm\n",
    "import matplotlib.mlab as mlab\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import copy\n",
    "\n",
    "import sys\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"pop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg = \"metal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"data/lyrics_final_clean.csv\"\n",
    "lyrics_df = pd.read_csv(filepath)\n",
    "lyrics_df = lyrics_df.dropna(axis = 0, how='any', subset=['lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(file_name):\n",
    "    with codecs.open(file_name, 'r', 'utf-8') as f_in:\n",
    "        lines = f_in.readlines()\n",
    "        lines = lines[1:]\n",
    "        vocabulary, wv = zip(*[line.strip().split(' ', 1) for line in lines])\n",
    "    wv = np.loadtxt(wv)\n",
    "    return wv, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings_src, vocabulary_src = load_embeddings('data/MUSE/model_lyrics_'+src+'.vec')\n",
    "word_embeddings_trg, vocabulary_trg = load_embeddings('data/MUSE/model_lyrics_'+trg+'.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_src = list(vocabulary_src)\n",
    "voc_trg = list(vocabulary_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = set(voc_src).intersection(set(voc_trg))\n",
    "common_words = list(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_specific_from_trg = set(voc_src).difference(set(common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(src_specific_from_trg, open(\"webpage/\"+src+\"/specific_from_\"+trg+\".py\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_src = list(lyrics_df[lyrics_df['genre'] == src]['lyrics'])\n",
    "corpus_src = [x.replace('\\n', ' ') for x in corpus_src]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(corpus, max_freq, min_freq):\n",
    "    #We use the stop_words parameter to remove the current words from the computations\n",
    "    tf = TfidfVectorizer(stop_words='english', max_df=max_freq, min_df=min_freq)\n",
    "    X = tf.fit(corpus)\n",
    "    X_transformed = X.transform(corpus)\n",
    "    #Find maximum value for each of the features over all of dataset\n",
    "    max_val = X_transformed.max(axis=0).toarray().ravel()\n",
    "\n",
    "    feature_names = np.array(tf.get_feature_names())\n",
    "    sorted_by_idf = np.argsort(tf.idf_)\n",
    "    #sort weights from smallest to biggest and extract their indices \n",
    "    sort_by_tfidf = max_val.argsort()\n",
    "    return feature_names[sort_by_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emma/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "tfidf_src = get_tfidf(corpus_src, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf_src, open(\"webpage/\"+src+\"/tfidf.py\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCH = 50\n",
    "BATCH_SIZE = 32\n",
    "N_ITERATION = round(len(voc_src)/BATCH_SIZE)\n",
    "REFINEMENT = 50 #Refinement is for the Procrustes Iterations, involved in the rotation of the embeddings\n",
    "INPUT_GENRE = src\n",
    "OUTPUT_GENRE = trg\n",
    "MODEL_ROCK = 'data/MUSE/model_lyrics_'+ INPUT_GENRE +'.vec'\n",
    "MODEL_POP = 'data/MUSE/model_lyrics_'+ OUTPUT_GENRE+'.vec'\n",
    "SRC_LANG = 'MUSE_'+ INPUT_GENRE\n",
    "TGT_LANG = 'MUSE_'+ OUTPUT_GENRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use the following method to spare us the very long output and directly extract the result\n",
    "def analyse_run(data):\n",
    "    data = ' '.join(data)\n",
    "    #You can change the path by analysing the logs in MUSE-master/dumped/debug\n",
    "    dump = data.split('exp_path: /Users/emma/Cours/Sem_3/Lyrix/REPORT/data/MUSE/MUSE-master/dumped/debug/')[1].split(' ')[0]\n",
    "    substring = data.split('* Best value for \"mean_cosine-csls_knn_10-S2T-10000\": ')[-1]\n",
    "    iteration = substring.split('End of ')[1].split('. ')[0]\n",
    "    best_mean_cosine = substring.split(' INFO')[0]\n",
    "    print(\"For dump \", dump, \" the best mean cosine was \", best_mean_cosine, \" reached at \", iteration)\n",
    "    return dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dump  vlrd6t95c2  the best mean cosine was  0.59400  reached at  refinement iteration 29\n"
     ]
    }
   ],
   "source": [
    "data = ! python data/MUSE/MUSE-master/unsupervised.py --src_lang $SRC_LANG --tgt_lang $TGT_LANG --src_emb $MODEL_ROCK --tgt_emb $MODEL_POP --n_epochs $N_EPOCH --epoch_size $N_ITERATION --batch_size $BATCH_SIZE --n_refinement $REFINEMENT\n",
    "dump = analyse_run(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pop -> rock : For dump  phymmrk0jd  the best mean cosine was  0.59956  reached at  refinement iteration 49\n",
    "- pop -> metal : For dump  nslut4e44p  the best mean cosine was  0.60609  reached at  refinement iteration 49\n",
    "- rock -> hip hop :For dump  vlrd6t95c2  the best mean cosine was  0.59400  reached at  refinement iteration 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = \"nslut4e44p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_muse_emb = \"data/MUSE/MUSE-master/dumped/debug/\"+ dump + \"/vectors-\"+ SRC_LANG + \".txt\"\n",
    "trg_muse_emb = \"data/MUSE/MUSE-master/dumped/debug/\"+ dump + \"/vectors-\"+ TGT_LANG + \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "muse_emb_src, muse_voc_src = load_embeddings(src_muse_emb)\n",
    "muse_emb_trg, muse_voc_trg = load_embeddings(trg_muse_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(muse_emb_trg, open(\"webpage/\"+trg+\"/muse_emb_with_\"+src+\".py\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=3, p=2, radius=1.0)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_trg = NearestNeighbors(n_neighbors=3)\n",
    "neigh_trg.fit(muse_emb_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(embed, voc):\n",
    "    voc_embeds_dict = {}\n",
    "    embeds_voc_dict = {}\n",
    "    for v, emb in zip(voc, embed):\n",
    "        voc_embeds_dict[v] = tuple(emb)\n",
    "        embeds_voc_dict[tuple(emb)] = v\n",
    "    return voc_embeds_dict, embeds_voc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "muse_voc2embed_src, _ = get_dict(muse_emb_src, muse_voc_src) \n",
    "_, muse_embed2voc_trg = get_dict(muse_emb_trg, muse_voc_trg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(muse_voc2embed_src, open(\"webpage/\"+src+\"/muse_voc2embed_with_\"+trg+\".py\", \"wb\"))\n",
    "pickle.dump(muse_embed2voc_trg, open(\"webpage/\"+trg+\"/muse_embed2voc_with_\"+src+\".py\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
