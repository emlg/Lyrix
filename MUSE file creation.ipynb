{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper notebook\n",
    "The goal of this notebook is to provide a pipeline of functions to create all the necessary files to run the demo of the MUSE procedure with the given pair of genres. <br>\n",
    "\n",
    "In order to use the following code, please follow those steps:\n",
    "- Make sure you have all the necessary libraries installed so that the import cell works\n",
    "- Choose your pair of genre in the following list ['pop', 'rock', 'hiphop', 'metal', 'jazz', 'country']\n",
    "- Enter the first genre as the 'src' variable\n",
    "- Enter the second genre as the 'trg' variable\n",
    "- You can then run all the cells in order: you will have to update the path to the MUSE-master dump repository in the 'analyse_run' function\n",
    "- Once this is done, you can launch the demo and explore the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "#MUSE Part\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import sys\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genre of the lyrics\n",
    "src = \"pop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genre from which we want the replacement words\n",
    "trg = \"metal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset to make the computations\n",
    "filepath = \"data/lyrics_final_clean.csv\"\n",
    "lyrics_df = pd.read_csv(filepath)\n",
    "lyrics_df = lyrics_df.dropna(axis = 0, how='any', subset=['lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load the embeddings from muse and fasttext\n",
    "def load_embeddings(file_name):\n",
    "    with codecs.open(file_name, 'r', 'utf-8') as f_in:\n",
    "        lines = f_in.readlines()\n",
    "        lines = lines[1:]\n",
    "        vocabulary, wv = zip(*[line.strip().split(' ', 1) for line in lines])\n",
    "    wv = np.loadtxt(wv)\n",
    "    return wv, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre-computed FastText embeddings from the 2 relevant genres\n",
    "word_embeddings_src, vocabulary_src = load_embeddings('data/MUSE/model_lyrics_'+src+'.vec')\n",
    "word_embeddings_trg, vocabulary_trg = load_embeddings('data/MUSE/model_lyrics_'+trg+'.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract list of vocabularies to compute specific vocabulary\n",
    "voc_src = list(vocabulary_src)\n",
    "voc_trg = list(vocabulary_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the words present in both vocabularies\n",
    "common_words = set(voc_src).intersection(set(voc_trg))\n",
    "common_words = list(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the specific words\n",
    "src_specific_from_trg = set(voc_src).difference(set(common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the specific vocabulary\n",
    "pickle.dump(src_specific_from_trg, open(\"webpage/\"+src+\"/specific_from_\"+trg+\".py\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract all the corpus of source genre to compute the TF-IDF ranking\n",
    "#(cannot use the .txt files as we need the separation by songs and .txt files is all songs concatenated)\n",
    "corpus_src = list(lyrics_df[lyrics_df['genre'] == src]['lyrics'])\n",
    "corpus_src = [x.replace('\\n', ' ') for x in corpus_src]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function giving the TF-IDF ranking of the vocabulary of one genre\n",
    "def get_tfidf(corpus, max_freq, min_freq):\n",
    "    #We use the stop_words parameter to remove the current words from the computations\n",
    "    tf = TfidfVectorizer(stop_words='english', max_df=max_freq, min_df=min_freq)\n",
    "    X = tf.fit(corpus)\n",
    "    X_transformed = X.transform(corpus)\n",
    "    #Find maximum value for each of the features over all of dataset\n",
    "    max_val = X_transformed.max(axis=0).toarray().ravel()\n",
    "\n",
    "    feature_names = np.array(tf.get_feature_names())\n",
    "    sorted_by_idf = np.argsort(tf.idf_)\n",
    "    #sort weights from smallest to biggest and extract their indices \n",
    "    sort_by_tfidf = max_val.argsort()\n",
    "    return feature_names[sort_by_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emma/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "#Compute the ordering (parameters can limit the max and min frequency)\n",
    "tfidf_src = get_tfidf(corpus_src, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the tf-idf file (should not depend on target genre, so you might already have it)\n",
    "pickle.dump(tfidf_src, open(\"webpage/\"+src+\"/tfidf.py\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set all parameters to compute the MUSE embedding --> The important and time-consuming part\n",
    "N_EPOCH = 50\n",
    "BATCH_SIZE = 32\n",
    "N_ITERATION = round(len(voc_src)/BATCH_SIZE)\n",
    "REFINEMENT = 50 #Refinement is for the Procrustes Iterations, involved in the rotation of the embeddings\n",
    "INPUT_GENRE = src\n",
    "OUTPUT_GENRE = trg\n",
    "MODEL_ROCK = 'data/MUSE/model_lyrics_'+ INPUT_GENRE +'.vec'\n",
    "MODEL_POP = 'data/MUSE/model_lyrics_'+ OUTPUT_GENRE+'.vec'\n",
    "SRC_LANG = 'MUSE_'+ INPUT_GENRE\n",
    "TGT_LANG = 'MUSE_'+ OUTPUT_GENRE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, you will need to change the path to the data/MUSE/MUSE-master/dumped/debug repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use the following method to spare us the very long output and directly extract the result\n",
    "def analyse_run(data):\n",
    "    data = ' '.join(data)\n",
    "    #You can change the path by analysing the logs in MUSE-master/dumped/debug\n",
    "    dump = data.split('exp_path: /Users/emma/Cours/Sem_3/Lyrix/REPORT/data/MUSE/MUSE-master/dumped/debug/')[1].split(' ')[0]\n",
    "    substring = data.split('* Best value for \"mean_cosine-csls_knn_10-S2T-10000\": ')[-1]\n",
    "    iteration = substring.split('End of ')[1].split('. ')[0]\n",
    "    best_mean_cosine = substring.split(' INFO')[0]\n",
    "    print(\"For dump \", dump, \" the best mean cosine was \", best_mean_cosine, \" reached at \", iteration)\n",
    "    return dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dump  vlrd6t95c2  the best mean cosine was  0.59400  reached at  refinement iteration 29\n"
     ]
    }
   ],
   "source": [
    "#Time consuming cell\n",
    "data = ! python data/MUSE/MUSE-master/unsupervised.py --src_lang $SRC_LANG --tgt_lang $TGT_LANG --src_emb $MODEL_ROCK --tgt_emb $MODEL_POP --n_epochs $N_EPOCH --epoch_size $N_ITERATION --batch_size $BATCH_SIZE --n_refinement $REFINEMENT\n",
    "dump = analyse_run(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the files containing the MUSE embeddings previously computed\n",
    "src_muse_emb = \"data/MUSE/MUSE-master/dumped/debug/\"+ dump + \"/vectors-\"+ SRC_LANG + \".txt\"\n",
    "trg_muse_emb = \"data/MUSE/MUSE-master/dumped/debug/\"+ dump + \"/vectors-\"+ TGT_LANG + \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the embeddings\n",
    "muse_emb_src, muse_voc_src = load_embeddings(src_muse_emb)\n",
    "muse_emb_trg, muse_voc_trg = load_embeddings(trg_muse_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Save the target embeddings\n",
    "pickle.dump(muse_emb_trg, open(\"webpage/\"+trg+\"/muse_emb_with_\"+src+\".py\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function needed to map the embeddings to the vocabulary in a nicer way\n",
    "def get_dict(embed, voc):\n",
    "    voc_embeds_dict = {}\n",
    "    embeds_voc_dict = {}\n",
    "    for v, emb in zip(voc, embed):\n",
    "        voc_embeds_dict[v] = tuple(emb)\n",
    "        embeds_voc_dict[tuple(emb)] = v\n",
    "    return voc_embeds_dict, embeds_voc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the necessary dictionnaries\n",
    "muse_voc2embed_src, _ = get_dict(muse_emb_src, muse_voc_src) \n",
    "_, muse_embed2voc_trg = get_dict(muse_emb_trg, muse_voc_trg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the dictionaries\n",
    "pickle.dump(muse_voc2embed_src, open(\"webpage/\"+src+\"/muse_voc2embed_with_\"+trg+\".py\", \"wb\"))\n",
    "pickle.dump(muse_embed2voc_trg, open(\"webpage/\"+trg+\"/muse_embed2voc_with_\"+src+\".py\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
