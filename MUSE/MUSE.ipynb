{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal of notebook \n",
    "- Create word model for pop and rock\n",
    "- Compute embeddings for words in pop and rock\n",
    "- Apply MUSE matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>pop</td>\n",
       "      <td>Oh baby how you doing\\nYou know I'm gonna cut ...</td>\n",
       "      <td>ego-remix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>pop</td>\n",
       "      <td>playin' everything so easy\\nit's like you seem...</td>\n",
       "      <td>then-tell-me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>pop</td>\n",
       "      <td>If you search\\nFor tenderness\\nIt isn't hard t...</td>\n",
       "      <td>honesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>pop</td>\n",
       "      <td>Oh oh oh I oh oh oh I\\n\\nIf I wrote a book abo...</td>\n",
       "      <td>you-are-my-rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>pop</td>\n",
       "      <td>Party the people the people the party it's pop...</td>\n",
       "      <td>black-culture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist genre                                             lyrics  \\\n",
       "0  beyonce-knowles   pop  Oh baby how you doing\\nYou know I'm gonna cut ...   \n",
       "1  beyonce-knowles   pop  playin' everything so easy\\nit's like you seem...   \n",
       "2  beyonce-knowles   pop  If you search\\nFor tenderness\\nIt isn't hard t...   \n",
       "3  beyonce-knowles   pop  Oh oh oh I oh oh oh I\\n\\nIf I wrote a book abo...   \n",
       "4  beyonce-knowles   pop  Party the people the people the party it's pop...   \n",
       "\n",
       "              song  \n",
       "0        ego-remix  \n",
       "1     then-tell-me  \n",
       "2          honesty  \n",
       "3  you-are-my-rock  \n",
       "4    black-culture  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"lyrics_final_clean.csv\"\n",
    "lyrics_df = pd.read_csv(filepath)\n",
    "lyrics_df = lyrics_df.dropna(axis = 0, how='any', subset=['lyrics'])\n",
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings (Fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrat specific genre lyrics\n",
    "def extract_genre_lyrics(g):\n",
    "    f = open(\"lyrics_\"+g+\".txt\", \"w+\")\n",
    "    for i, r in lyrics_df[lyrics_df['genre'] == g].iterrows():\n",
    "        text = r['lyrics']+ '\\n'\n",
    "        text = text.lower()\n",
    "        text = text.replace(\"'\", ' ')\n",
    "        f.write(text)\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_genre_lyrics('pop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_genre_lyrics('rock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 16M words\n",
      "Number of words:  29549\n",
      "Number of labels: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 48.0%  words/sec/thread: 285192  lr: 0.026017  loss: 1.994570  eta: 0h0m   words/sec/thread: 12029  lr: 0.049895  loss: 4.074791  eta: 0h9m   lr: 0.049740  loss: 3.411579  eta: 0h4m   lr: 0.049619  loss: 3.076413  eta: 0h2m   loss: 2.893054  eta: 0h2m m   eta: 0h1m hread: 110384  lr: 0.048597  loss: 2.544579  eta: 0h1m /thread: 112257  lr: 0.048561  loss: 2.536121  eta: 0h1m hread: 114529  lr: 0.048517  loss: 2.522033  eta: 0h0m 2.460153  eta: 0h0m 3.7%  words/sec/thread: 131223  lr: 0.048157  loss: 2.455158  eta: 0h0m %  words/sec/thread: 136387  lr: 0.048032  loss: 2.434868  eta: 0h0m hread: 137878  lr: 0.047993  loss: 2.431771  eta: 0h0m hread: 147843  lr: 0.047732  loss: 2.391124  eta: 0h0m hread: 149125  lr: 0.047695  loss: 2.383582  eta: 0h0m hread: 160388  lr: 0.047370  loss: 2.348550  eta: 0h0m hread: 163663  lr: 0.047266  loss: 2.333563  eta: 0h0m ec/thread: 174601  lr: 0.046859  loss: 2.290448  eta: 0h0m ec/thread: 180164  lr: 0.046634  loss: 2.269885  eta: 0h0m h0m hread: 182950  lr: 0.046523  loss: 2.258419  eta: 0h0m hread: 188274  lr: 0.046288  loss: 2.247679  eta: 0h0m a: 0h0m hread: 193157  lr: 0.046041  loss: 2.227921  eta: 0h0m hread: 194970  lr: 0.045933  loss: 2.224691  eta: 0h0m   loss: 2.222514  eta: 0h0m 8.6%  words/sec/thread: 199189  lr: 0.045685  loss: 2.214633  eta: 0h0m hread: 200149  lr: 0.045619  loss: 2.212993  eta: 0h0m hread: 200537  lr: 0.045590  loss: 2.212006  eta: 0h0m hread: 202337  lr: 0.045478  loss: 2.205060  eta: 0h0m hread: 204042  lr: 0.045374  loss: 2.203611  eta: 0h0m 0h0m   words/sec/thread: 209785  lr: 0.045011  loss: 2.193934  eta: 0h0m   words/sec/thread: 211531  lr: 0.044900  loss: 2.189868  eta: 0h0m 0.044792  loss: 2.184576  eta: 0h0m   words/sec/thread: 214436  lr: 0.044682  loss: 2.181332  eta: 0h0m 214772  lr: 0.044656  loss: 2.180032  eta: 0h0m   words/sec/thread: 217662  lr: 0.044454  loss: 2.172727  eta: 0h0m   words/sec/thread: 218291  lr: 0.044412  loss: 2.170711  eta: 0h0m 0m   words/sec/thread: 219681  lr: 0.044306  loss: 2.164579  eta: 0h0m   words/sec/thread: 220705  lr: 0.044228  loss: 2.162650  eta: 0h0m loss: 2.155021  eta: 0h0m /thread: 225448  lr: 0.043850  loss: 2.146991  eta: 0h0m   lr: 0.043622  loss: 2.137350  eta: 0h0m 12.9%  words/sec/thread: 229063  lr: 0.043537  loss: 2.135738  eta: 0h0m hread: 229970  lr: 0.043438  loss: 2.133307  eta: 0h0m 0m   lr: 0.043303  loss: 2.131310  eta: 0h0m   words/sec/thread: 232061  lr: 0.043218  loss: 2.130971  eta: 0h0m h0m ad: 236197  lr: 0.042801  loss: 2.125095  eta: 0h0m   words/sec/thread: 236496  lr: 0.042767  loss: 2.125513  eta: 0h0m   words/sec/thread: 238125  lr: 0.042581  loss: 2.121585  eta: 0h0m   words/sec/thread: 241148  lr: 0.042247  loss: 2.114836  eta: 0h0m 15.7%  words/sec/thread: 242142  lr: 0.042132  loss: 2.112617  eta: 0h0m   words/sec/thread: 244155  lr: 0.041873  loss: 2.107442  eta: 0h0m 246546  lr: 0.041564  loss: 2.101045  eta: 0h0m ead: 247545  lr: 0.041397  loss: 2.100305  eta: 0h0m 0.041289  loss: 2.099423  eta: 0h0m 0m   words/sec/thread: 251716  lr: 0.040793  loss: 2.096384  eta: 0h0m   words/sec/thread: 253106  lr: 0.040561  loss: 2.094818  eta: 0h0m 253508  lr: 0.040480  loss: 2.093183  eta: 0h0m 19.2%  words/sec/thread: 253899  lr: 0.040417  loss: 2.092623  eta: 0h0m   words/sec/thread: 256863  lr: 0.039904  loss: 2.087789  eta: 0h0m   eta: 0h0m   words/sec/thread: 258480  lr: 0.039572  loss: 2.082602  eta: 0h0m hread: 259273  lr: 0.039418  loss: 2.080858  eta: 0h0m 0.039410  loss: 2.080904  eta: 0h0m   words/sec/thread: 261118  lr: 0.039051  loss: 2.080504  eta: 0h0m 2.079508  eta: 0h0m   words/sec/thread: 262723  lr: 0.038769  loss: 2.079318  eta: 0h0m   eta: 0h0m 23.0%  words/sec/thread: 263962  lr: 0.038483  loss: 2.075000  eta: 0h0m   words/sec/thread: 264166  lr: 0.038443  loss: 2.074934  eta: 0h0m ad: 264661  lr: 0.038331  loss: 2.075023  eta: 0h0m 265386  lr: 0.038180  loss: 2.074087  eta: 0h0m   words/sec/thread: 266051  lr: 0.038033  loss: 2.072878  eta: 0h0m   words/sec/thread: 266237  lr: 0.037990  loss: 2.073100  eta: 0h0m   words/sec/thread: 266765  lr: 0.037874  loss: 2.072033  eta: 0h0m   words/sec/thread: 266843  lr: 0.037846  loss: 2.070401  eta: 0h0m   words/sec/thread: 267479  lr: 0.037667  loss: 2.067871  eta: 0h0m   words/sec/thread: 267768  lr: 0.037561  loss: 2.067702  eta: 0h0m   eta: 0h0m 0m   words/sec/thread: 269140  lr: 0.037009  loss: 2.065677  eta: 0h0m 26.0%  words/sec/thread: 269207  lr: 0.036988  loss: 2.065708  eta: 0h0m   words/sec/thread: 269813  lr: 0.036730  loss: 2.065715  eta: 0h0m   loss: 2.066916  eta: 0h0m   loss: 2.066175  eta: 0h0m   words/sec/thread: 270627  lr: 0.036464  loss: 2.065560  eta: 0h0m 0h0m   words/sec/thread: 271436  lr: 0.036182  loss: 2.062273  eta: 0h0m   words/sec/thread: 271832  lr: 0.036063  loss: 2.062122  eta: 0h0m   words/sec/thread: 272197  lr: 0.035920  loss: 2.060065  eta: 0h0m   words/sec/thread: 272454  lr: 0.035846  loss: 2.059180  eta: 0h0m   words/sec/thread: 272827  lr: 0.035733  loss: 2.058197  eta: 0h0m 28.6%  words/sec/thread: 272848  lr: 0.035716  loss: 2.057017  eta: 0h0m ad: 273001  lr: 0.035659  loss: 2.056282  eta: 0h0m 0m   eta: 0h0m 273867  lr: 0.035313  loss: 2.053832  eta: 0h0m   words/sec/thread: 274268  lr: 0.035136  loss: 2.054471  eta: 0h0m   words/sec/thread: 274402  lr: 0.035066  loss: 2.053750  eta: 0h0m ad: 274480  lr: 0.035030  loss: 2.053128  eta: 0h0m ad: 274917  lr: 0.034846  loss: 2.052161  eta: 0h0m 30.4%  words/sec/thread: 275020  lr: 0.034778  loss: 2.051535  eta: 0h0m   words/sec/thread: 275166  lr: 0.034707  loss: 2.051155  eta: 0h0m   words/sec/thread: 275261  lr: 0.034674  loss: 2.051084  eta: 0h0m   words/sec/thread: 275420  lr: 0.034593  loss: 2.050355  eta: 0h0m   words/sec/thread: 275680  lr: 0.034492  loss: 2.049984  eta: 0h0m 0h0m m   words/sec/thread: 276681  lr: 0.033913  loss: 2.046326  eta: 0h0m   words/sec/thread: 277046  lr: 0.033731  loss: 2.045434  eta: 0h0m h0m 33.6%  words/sec/thread: 278188  lr: 0.033194  loss: 2.041544  eta: 0h0m   words/sec/thread: 278755  lr: 0.032879  loss: 2.037005  eta: 0h0m   words/sec/thread: 279260  lr: 0.032597  loss: 2.030371  eta: 0h0m h0m ad: 279897  lr: 0.032048  loss: 2.031810  eta: 0h0m   words/sec/thread: 280083  lr: 0.031915  loss: 2.031219  eta: 0h0m 0.031847  loss: 2.030629  eta: 0h0m   loss: 2.029762  eta: 0h0m   words/sec/thread: 280415  lr: 0.031742  loss: 2.028907  eta: 0h0m 0m 2.027489  eta: 0h0m   words/sec/thread: 280631  lr: 0.031322  loss: 2.027229  eta: 0h0m   words/sec/thread: 280745  lr: 0.031184  loss: 2.025384  eta: 0h0m   words/sec/thread: 280985  lr: 0.031076  loss: 2.024472  eta: 0h0m 0m loss: 2.022985  eta: 0h0m loss: 2.022525  eta: 0h0m   words/sec/thread: 281698  lr: 0.030267  loss: 2.021656  eta: 0h0m ad: 281752  lr: 0.030196  loss: 2.021621  eta: 0h0m 0h0m   words/sec/thread: 281950  lr: 0.029995  loss: 2.019302  eta: 0h0m 0.029877  loss: 2.019138  eta: 0h0m   words/sec/thread: 282350  lr: 0.029689  loss: 2.017538  eta: 0h0m   words/sec/thread: 282404  lr: 0.029654  loss: 2.017422  eta: 0h0m   words/sec/thread: 282444  lr: 0.029619  loss: 2.016908  eta: 0h0m 0.029517  loss: 2.015105  eta: 0h0m   words/sec/thread: 282595  lr: 0.029478  loss: 2.015007  eta: 0h0m   eta: 0h0m 0.028789  loss: 2.011188  eta: 0h0m   words/sec/thread: 283172  lr: 0.028369  loss: 2.009365  eta: 0h0m   words/sec/thread: 283229  lr: 0.028301  loss: 2.009297  eta: 0h0m %  words/sec/thread: 283545  lr: 0.028059  loss: 2.008375  eta: 0h0m 0.028029  loss: 2.008060  eta: 0h0m 0m   words/sec/thread: 284098  lr: 0.027630  loss: 2.006334  eta: 0h0m 4.9%  words/sec/thread: 284236  lr: 0.027531  loss: 2.005714  eta: 0h0m   words/sec/thread: 284506  lr: 0.027290  loss: 2.003135  eta: 0h0m   words/sec/thread: 284722  lr: 0.027069  loss: 2.000405  eta: 0h0m 45.9%  words/sec/thread: 284742  lr: 0.027051  loss: 1.999660  eta: 0h0m h0m 0.026705  loss: 1.996891  eta: 0h0m h0m   words/sec/thread: 285040  lr: 0.026246  loss: 1.995376  eta: 0h0m %  words/sec/thread: 285072  lr: 0.026184  loss: 1.995065  eta: 0h0m   loss: 1.994799  eta: 0h0m   words/sec/thread: 285162  lr: 0.026048  loss: 1.994729  eta: 0h0m   words/sec/thread: 285193  lr: 0.026017  loss: 1.994564  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285192  lr: 0.026015  loss: 1.994566  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285192  lr: 0.026014  loss: 1.994557  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285193  lr: 0.026014  loss: 1.994553  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285189  lr: 0.026014  loss: 1.994558  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285190  lr: 0.026014  loss: 1.994556  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285188  lr: 0.026014  loss: 1.994545  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285187  lr: 0.026014  loss: 1.994535  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285188  lr: 0.026013  loss: 1.994541  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285193  lr: 0.026013  loss: 1.994525  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285192  lr: 0.026013  loss: 1.994532  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285193  lr: 0.026013  loss: 1.994537  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285194  lr: 0.026012  loss: 1.994543  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285193  lr: 0.026012  loss: 1.994553  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285195  lr: 0.026012  loss: 1.994557  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285194  lr: 0.026012  loss: 1.994572  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285195  lr: 0.026012  loss: 1.994596  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285195  lr: 0.026012  loss: 1.994582  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285196  lr: 0.026012  loss: 1.994581  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285196  lr: 0.026012  loss: 1.994581  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285197  lr: 0.026011  loss: 1.994589  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285197  lr: 0.026011  loss: 1.994585  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285198  lr: 0.026011  loss: 1.994577  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285193  lr: 0.026011  loss: 1.994575  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285193  lr: 0.026011  loss: 1.994579  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285193  lr: 0.026010  loss: 1.994579  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285195  lr: 0.026010  loss: 1.994565  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285196  lr: 0.026010  loss: 1.994560  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285195  lr: 0.026010  loss: 1.994577  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285196  lr: 0.026010  loss: 1.994568  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285197  lr: 0.026010  loss: 1.994553  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285197  lr: 0.026009  loss: 1.994544  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285196  lr: 0.026009  loss: 1.994552  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285197  lr: 0.026009  loss: 1.994540  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285199  lr: 0.026009  loss: 1.994535  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285210  lr: 0.025985  loss: 1.994527  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285210  lr: 0.025985  loss: 1.994480  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285209  lr: 0.025984  loss: 1.994458  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285207  lr: 0.025984  loss: 1.994419  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285208  lr: 0.025984  loss: 1.994380  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285208  lr: 0.025984  loss: 1.994349  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285207  lr: 0.025984  loss: 1.994354  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285208  lr: 0.025984  loss: 1.994339  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285207  lr: 0.025983  loss: 1.994340  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285206  lr: 0.025983  loss: 1.994331  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285207  lr: 0.025983  loss: 1.994333  eta: 0h0m \r",
      "Progress: 48.0%  words/sec/thread: 285208  lr: 0.025983  loss: 1.994326  eta: 0h0m \r",
      "Progress: 48.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 72.9%  words/sec/thread: 287960  lr: 0.013561  loss: 1.945256  eta: 0h0m   words/sec/thread: 285260  lr: 0.025892  loss: 1.993766  eta: 0h0m   lr: 0.025831  loss: 1.993454  eta: 0h0m ad: 285247  lr: 0.025769  loss: 1.993389  eta: 0h0m 0h0m   eta: 0h0m   words/sec/thread: 285514  lr: 0.025478  loss: 1.991567  eta: 0h0m   words/sec/thread: 285638  lr: 0.025331  loss: 1.990626  eta: 0h0m h0m %  words/sec/thread: 285694  lr: 0.025261  loss: 1.990116  eta: 0h0m   words/sec/thread: 285757  lr: 0.025222  loss: 1.990181  eta: 0h0m /thread: 285780  lr: 0.025193  loss: 1.990182  eta: 0h0m ead: 285843  lr: 0.025152  loss: 1.990350  eta: 0h0m   words/sec/thread: 285854  lr: 0.025120  loss: 1.990456  eta: 0h0m h0m   words/sec/thread: 285940  lr: 0.024995  loss: 1.989883  eta: 0h0m loss: 1.989595  eta: 0h0m   words/sec/thread: 286000  lr: 0.024913  loss: 1.989151  eta: 0h0m   words/sec/thread: 285996  lr: 0.024879  loss: 1.989102  eta: 0h0m   words/sec/thread: 286029  lr: 0.024782  loss: 1.988387  eta: 0h0m   words/sec/thread: 286012  lr: 0.024712  loss: 1.988188  eta: 0h0m m 286104  lr: 0.024600  loss: 1.986959  eta: 0h0m   words/sec/thread: 286140  lr: 0.024587  loss: 1.986957  eta: 0h0m   words/sec/thread: 286181  lr: 0.024527  loss: 1.986978  eta: 0h0m   words/sec/thread: 286198  lr: 0.024496  loss: 1.986757  eta: 0h0m   words/sec/thread: 286211  lr: 0.024430  loss: 1.986539  eta: 0h0m ad: 286311  lr: 0.024296  loss: 1.984698  eta: 0h0m 51.4%  words/sec/thread: 286303  lr: 0.024289  loss: 1.984584  eta: 0h0m loss: 1.984467  eta: 0h0m ad: 286468  lr: 0.024108  loss: 1.983845  eta: 0h0m 1.983364  eta: 0h0m   words/sec/thread: 286520  lr: 0.024051  loss: 1.983135  eta: 0h0m 05  loss: 1.981951  eta: 0h0m   words/sec/thread: 286860  lr: 0.023705  loss: 1.980480  eta: 0h0m ad: 287029  lr: 0.023589  loss: 1.979387  eta: 0h0m   eta: 0h0m 0.023439  loss: 1.978951  eta: 0h0m   words/sec/thread: 287224  lr: 0.023370  loss: 1.978641  eta: 0h0m   words/sec/thread: 287266  lr: 0.023329  loss: 1.978515  eta: 0h0m   words/sec/thread: 287297  lr: 0.023294  loss: 1.978462  eta: 0h0m 1.977821  eta: 0h0m m : 0.023173  loss: 1.977499  eta: 0h0m   loss: 1.978090  eta: 0h0m 0.022862  loss: 1.977848  eta: 0h0m   words/sec/thread: 287538  lr: 0.022793  loss: 1.977815  eta: 0h0m   words/sec/thread: 287570  lr: 0.022727  loss: 1.977327  eta: 0h0m   words/sec/thread: 287607  lr: 0.022704  loss: 1.976979  eta: 0h0m 2565  loss: 1.976730  eta: 0h0m   eta: 0h0m ad: 287774  lr: 0.022495  loss: 1.976462  eta: 0h0m 2399  loss: 1.976499  eta: 0h0m   words/sec/thread: 287922  lr: 0.022379  loss: 1.976360  eta: 0h0m   words/sec/thread: 287960  lr: 0.022327  loss: 1.976346  eta: 0h0m ad: 288097  lr: 0.022185  loss: 1.975637  eta: 0h0m ad: 288185  lr: 0.022080  loss: 1.974713  eta: 0h0m lr: 0.022054  loss: 1.974286  eta: 0h0m h0m 6.2%  words/sec/thread: 288321  lr: 0.021913  loss: 1.973437  eta: 0h0m ad: 288310  lr: 0.021828  loss: 1.972201  eta: 0h0m r: 0.021760  loss: 1.971944  eta: 0h0m   words/sec/thread: 288316  lr: 0.021702  loss: 1.971198  eta: 0h0m 0.021683  loss: 1.970736  eta: 0h0m   words/sec/thread: 288289  lr: 0.021625  loss: 1.970067  eta: 0h0m 1.969545  eta: 0h0m   words/sec/thread: 288321  lr: 0.021445  loss: 1.969517  eta: 0h0m 0.021396  loss: 1.969190  eta: 0h0m   eta: 0h0m   words/sec/thread: 288394  lr: 0.021184  loss: 1.968433  eta: 0h0m 1.968155  eta: 0h0m   eta: 0h0m ad: 288453  lr: 0.021020  loss: 1.967104  eta: 0h0m 58.1%  words/sec/thread: 288456  lr: 0.020970  loss: 1.967060  eta: 0h0m h0m   words/sec/thread: 288504  lr: 0.020813  loss: 1.966206  eta: 0h0m 0m 58.7%  words/sec/thread: 288274  lr: 0.020652  loss: 1.965459  eta: 0h0m m h0m   words/sec/thread: 288058  lr: 0.020426  loss: 1.964672  eta: 0h0m 1.963397  eta: 0h0m ad: 288146  lr: 0.019927  loss: 1.961269  eta: 0h0m 0m ad: 288234  lr: 0.019689  loss: 1.962240  eta: 0h0m 0.019621  loss: 1.962052  eta: 0h0m 0.019516  loss: 1.961901  eta: 0h0m   words/sec/thread: 288254  lr: 0.019408  loss: 1.961924  eta: 0h0m 61.6%  words/sec/thread: 288218  lr: 0.019214  loss: 1.961829  eta: 0h0m   words/sec/thread: 288219  lr: 0.019180  loss: 1.961827  eta: 0h0m ta: 0h0m   words/sec/thread: 288190  lr: 0.019091  loss: 1.961745  eta: 0h0m ad: 288129  lr: 0.018981  loss: 1.961234  eta: 0h0m   words/sec/thread: 288040  lr: 0.018876  loss: 1.961655  eta: 0h0m 0.018846  loss: 1.961330  eta: 0h0m ad: 288042  lr: 0.018752  loss: 1.961089  eta: 0h0m   words/sec/thread: 288027  lr: 0.018705  loss: 1.960630  eta: 0h0m h0m 0.018607  loss: 1.960014  eta: 0h0m   words/sec/thread: 288077  lr: 0.018444  loss: 1.960230  eta: 0h0m 3.2%  words/sec/thread: 288059  lr: 0.018412  loss: 1.960168  eta: 0h0m s: 63.2%  words/sec/thread: 288051  lr: 0.018395  loss: 1.960014  eta: 0h0m 0.018342  loss: 1.960097  eta: 0h0m   words/sec/thread: 287980  lr: 0.018276  loss: 1.959730  eta: 0h0m ad: 287978  lr: 0.018265  loss: 1.959612  eta: 0h0m   words/sec/thread: 287984  lr: 0.018174  loss: 1.959313  eta: 0h0m   words/sec/thread: 287978  lr: 0.018136  loss: 1.958918  eta: 0h0m 1.958870  eta: 0h0m 1.958643  eta: 0h0m 0.018001  loss: 1.958162  eta: 0h0m ad: 287947  lr: 0.017992  loss: 1.958004  eta: 0h0m 1.957863  eta: 0h0m thread: 287905  lr: 0.017896  loss: 1.957688  eta: 0h0m   words/sec/thread: 287883  lr: 0.017868  loss: 1.957381  eta: 0h0m 1.957234  eta: 0h0m 0.017787  loss: 1.957031  eta: 0h0m   words/sec/thread: 287841  lr: 0.017706  loss: 1.956576  eta: 0h0m 0.017660  loss: 1.956099  eta: 0h0m ad: 287876  lr: 0.017646  loss: 1.955961  eta: 0h0m   words/sec/thread: 287854  lr: 0.017561  loss: 1.955822  eta: 0h0m   words/sec/thread: 287859  lr: 0.017483  loss: 1.955744  eta: 0h0m   words/sec/thread: 287868  lr: 0.017447  loss: 1.955699  eta: 0h0m   words/sec/thread: 287865  lr: 0.017433  loss: 1.955869  eta: 0h0m   words/sec/thread: 287886  lr: 0.017348  loss: 1.956031  eta: 0h0m 287881  lr: 0.017329  loss: 1.955917  eta: 0h0m eta: 0h0m 0m   words/sec/thread: 287913  lr: 0.016995  loss: 1.954742  eta: 0h0m 1.954491  eta: 0h0m   words/sec/thread: 287915  lr: 0.016941  loss: 1.954281  eta: 0h0m ad: 287936  lr: 0.016791  loss: 1.954020  eta: 0h0m   words/sec/thread: 287922  lr: 0.016649  loss: 1.953656  eta: 0h0m ad: 287944  lr: 0.016600  loss: 1.953643  eta: 0h0m ad: 287956  lr: 0.016560  loss: 1.953476  eta: 0h0m   words/sec/thread: 287961  lr: 0.016482  loss: 1.953043  eta: 0h0m ad: 287953  lr: 0.016453  loss: 1.952774  eta: 0h0m 0.016437  loss: 1.952760  eta: 0h0m 0.016364  loss: 1.952694  eta: 0h0m ad: 287951  lr: 0.016167  loss: 1.952244  eta: 0h0m   words/sec/thread: 287951  lr: 0.016154  loss: 1.952023  eta: 0h0m   words/sec/thread: 287925  lr: 0.016008  loss: 1.951893  eta: 0h0m   words/sec/thread: 287951  lr: 0.015825  loss: 1.951728  eta: 0h0m ad: 287947  lr: 0.015672  loss: 1.950858  eta: 0h0m h0m 0.015583  loss: 1.950332  eta: 0h0m loss: 1.950015  eta: 0h0m 287917  lr: 0.015386  loss: 1.949325  eta: 0h0m ad: 287901  lr: 0.015311  loss: 1.949116  eta: 0h0m 0h0m ad: 287831  lr: 0.015150  loss: 1.949409  eta: 0h0m 1.949235  eta: 0h0m rds/sec/thread: 287797  lr: 0.015046  loss: 1.948938  eta: 0h0m ad: 287786  lr: 0.015040  loss: 1.948882  eta: 0h0m 0m   words/sec/thread: 287769  lr: 0.014926  loss: 1.948550  eta: 0h0m   words/sec/thread: 287777  lr: 0.014814  loss: 1.948257  eta: 0h0m ad: 287786  lr: 0.014743  loss: 1.948152  eta: 0h0m 70.9%  words/sec/thread: 287798  lr: 0.014558  loss: 1.946936  eta: 0h0m   words/sec/thread: 287852  lr: 0.014472  loss: 1.946844  eta: 0h0m ad: 287854  lr: 0.014400  loss: 1.946467  eta: 0h0m h0m   eta: 0h0m 1.945892  eta: 0h0m 0.014129  loss: 1.945960  eta: 0h0m   words/sec/thread: 287969  lr: 0.014090  loss: 1.945732  eta: 0h0m   words/sec/thread: 287963  lr: 0.014048  loss: 1.945531  eta: 0h0m 1.945417  eta: 0h0m   words/sec/thread: 287961  lr: 0.013987  loss: 1.945018  eta: 0h0m ad: 287968  lr: 0.013975  loss: 1.944830  eta: 0h0m ss: 1.944688  eta: 0h0m thread: 287939  lr: 0.013849  loss: 1.944348  eta: 0h0m 72.3%  words/sec/thread: 287928  lr: 0.013845  loss: 1.944403  eta: 0h0m m ad: 287947  lr: 0.013675  loss: 1.944996  eta: 0h0m /thread: 287967  lr: 0.013601  loss: 1.945307  eta: 0h0m 0.013569  loss: 1.945235  eta: 0h0m "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 93.2%  words/sec/thread: 287667  lr: 0.003399  loss: 1.901590  eta: 0h0m loss: 1.944730  eta: 0h0m 4631  eta: 0h0m 0.013181  loss: 1.944548  eta: 0h0m 0.013108  loss: 1.944481  eta: 0h0m ad: 288036  lr: 0.013073  loss: 1.944258  eta: 0h0m thread: 288033  lr: 0.013037  loss: 1.943786  eta: 0h0m   words/sec/thread: 288037  lr: 0.013027  loss: 1.943631  eta: 0h0m ad: 288035  lr: 0.012957  loss: 1.943119  eta: 0h0m 0.012882  loss: 1.943012  eta: 0h0m   words/sec/thread: 288041  lr: 0.012874  loss: 1.943024  eta: 0h0m   words/sec/thread: 288050  lr: 0.012792  loss: 1.942820  eta: 0h0m %  words/sec/thread: 288057  lr: 0.012764  loss: 1.942747  eta: 0h0m ad: 288080  lr: 0.012716  loss: 1.942714  eta: 0h0m   words/sec/thread: 288097  lr: 0.012632  loss: 1.942446  eta: 0h0m ad: 288081  lr: 0.012584  loss: 1.941552  eta: 0h0m   words/sec/thread: 288081  lr: 0.012505  loss: 1.941574  eta: 0h0m   words/sec/thread: 288087  lr: 0.012377  loss: 1.941373  eta: 0h0m ad: 288081  lr: 0.012361  loss: 1.941468  eta: 0h0m gress: 75.4%  words/sec/thread: 288101  lr: 0.012297  loss: 1.941028  eta: 0h0m thread: 288102  lr: 0.012284  loss: 1.940957  eta: 0h0m ad: 288121  lr: 0.012219  loss: 1.940827  eta: 0h0m   words/sec/thread: 288121  lr: 0.012210  loss: 1.940741  eta: 0h0m 5.7%  words/sec/thread: 288167  lr: 0.012129  loss: 1.940401  eta: 0h0m   words/sec/thread: 288174  lr: 0.012054  loss: 1.940189  eta: 0h0m ad: 288174  lr: 0.012004  loss: 1.939808  eta: 0h0m ad: 288156  lr: 0.011988  loss: 1.939767  eta: 0h0m 1.939536  eta: 0h0m 0.011767  loss: 1.939295  eta: 0h0m 1762  loss: 1.939285  eta: 0h0m ad: 288169  lr: 0.011557  loss: 1.938423  eta: 0h0m   words/sec/thread: 288170  lr: 0.011548  loss: 1.938401  eta: 0h0m 1.938353  eta: 0h0m   words/sec/thread: 288181  lr: 0.011420  loss: 1.937964  eta: 0h0m 7.2%  words/sec/thread: 288174  lr: 0.011402  loss: 1.937810  eta: 0h0m 0.011328  loss: 1.937634  eta: 0h0m   words/sec/thread: 288120  lr: 0.011266  loss: 1.937263  eta: 0h0m 1.937151  eta: 0h0m 0.011189  loss: 1.936805  eta: 0h0m ad: 288154  lr: 0.011105  loss: 1.936349  eta: 0h0m .9%  words/sec/thread: 288174  lr: 0.011044  loss: 1.935980  eta: 0h0m s: 1.935930  eta: 0h0m   words/sec/thread: 288177  lr: 0.010954  loss: 1.935844  eta: 0h0m 0.010911  loss: 1.935791  eta: 0h0m 1.935710  eta: 0h0m 1.935490  eta: 0h0m 78.7%  words/sec/thread: 288155  lr: 0.010673  loss: 1.934978  eta: 0h0m  lr: 0.010665  loss: 1.934846  eta: 0h0m 0.010598  loss: 1.934639  eta: 0h0m ad: 288139  lr: 0.010542  loss: 1.934284  eta: 0h0m 0h0m h0m sec/thread: 288146  lr: 0.010381  loss: 1.933401  eta: 0h0m   eta: 0h0m ad: 288051  lr: 0.010116  loss: 1.932085  eta: 0h0m 0.010112  loss: 1.932083  eta: 0h0m 0.010039  loss: 1.931754  eta: 0h0m   words/sec/thread: 288027  lr: 0.009969  loss: 1.931752  eta: 0h0m   words/sec/thread: 288019  lr: 0.009901  loss: 1.931544  eta: 0h0m 0.009832  loss: 1.931329  eta: 0h0m   words/sec/thread: 287985  lr: 0.009761  loss: 1.931300  eta: 0h0m ad: 287993  lr: 0.009756  loss: 1.931337  eta: 0h0m ad: 287952  lr: 0.009684  loss: 1.931476  eta: 0h0m ad: 287906  lr: 0.009592  loss: 1.931712  eta: 0h0m   words/sec/thread: 287896  lr: 0.009561  loss: 1.931781  eta: 0h0m   words/sec/thread: 287906  lr: 0.009549  loss: 1.931733  eta: 0h0m ad: 287923  lr: 0.009472  loss: 1.931561  eta: 0h0m 0.009422  loss: 1.931472  eta: 0h0m h0m gress: 81.5%  words/sec/thread: 287963  lr: 0.009262  loss: 1.931241  eta: 0h0m 1138  eta: 0h0m   words/sec/thread: 287996  lr: 0.009145  loss: 1.931092  eta: 0h0m   words/sec/thread: 287984  lr: 0.009100  loss: 1.930931  eta: 0h0m 2.0%  words/sec/thread: 287976  lr: 0.008998  loss: 1.931052  eta: 0h0m 0.008971  loss: 1.930539  eta: 0h0m ad: 287943  lr: 0.008883  loss: 1.929748  eta: 0h0m   words/sec/thread: 287919  lr: 0.008814  loss: 1.928412  eta: 0h0m 2.5%  words/sec/thread: 287915  lr: 0.008758  loss: 1.927452  eta: 0h0m ead: 287922  lr: 0.008712  loss: 1.926920  eta: 0h0m ad: 287905  lr: 0.008672  loss: 1.925765  eta: 0h0m 0.008568  loss: 1.924359  eta: 0h0m h0m   words/sec/thread: 287940  lr: 0.008372  loss: 1.921235  eta: 0h0m ad: 287914  lr: 0.008303  loss: 1.919716  eta: 0h0m   words/sec/thread: 287906  lr: 0.008217  loss: 1.918208  eta: 0h0m 1.917581  eta: 0h0m 3.7%  words/sec/thread: 287929  lr: 0.008145  loss: 1.917328  eta: 0h0m 1.916611  eta: 0h0m oss: 1.916505  eta: 0h0m 1.916507  eta: 0h0m   words/sec/thread: 287934  lr: 0.007929  loss: 1.916460  eta: 0h0m   eta: 0h0m ad: 287993  lr: 0.007782  loss: 1.915739  eta: 0h0m ad: 288025  lr: 0.007701  loss: 1.915426  eta: 0h0m 0.007634  loss: 1.915189  eta: 0h0m s: 84.9%  words/sec/thread: 288071  lr: 0.007558  loss: 1.914956  eta: 0h0m   words/sec/thread: 288062  lr: 0.007549  loss: 1.915016  eta: 0h0m   words/sec/thread: 288098  lr: 0.007477  loss: 1.914663  eta: 0h0m lr: 0.007327  loss: 1.914110  eta: 0h0m 0.007271  loss: 1.914249  eta: 0h0m h0m   words/sec/thread: 288094  lr: 0.007184  loss: 1.914209  eta: 0h0m 0.007113  loss: 1.914118  eta: 0h0m h0m /thread: 288062  lr: 0.006976  loss: 1.913793  eta: 0h0m ta: 0h0m eta: 0h0m   words/sec/thread: 288081  lr: 0.006827  loss: 1.913291  eta: 0h0m ad: 288076  lr: 0.006820  loss: 1.913275  eta: 0h0m 1.913206  eta: 0h0m 0.006719  loss: 1.912994  eta: 0h0m 0.006615  loss: 1.912589  eta: 0h0m 6.9%  words/sec/thread: 288123  lr: 0.006562  loss: 1.912218  eta: 0h0m   words/sec/thread: 288128  lr: 0.006543  loss: 1.911937  eta: 0h0m h0m s: 87.2%  words/sec/thread: 288162  lr: 0.006400  loss: 1.911335  eta: 0h0m ad: 288171  lr: 0.006388  loss: 1.911257  eta: 0h0m   words/sec/thread: 288167  lr: 0.006251  loss: 1.910548  eta: 0h0m ad: 288171  lr: 0.006246  loss: 1.910536  eta: 0h0m   words/sec/thread: 288180  lr: 0.006114  loss: 1.909883  eta: 0h0m ess: 87.9%  words/sec/thread: 288210  lr: 0.006033  loss: 1.909626  eta: 0h0m 8.0%  words/sec/thread: 288212  lr: 0.005985  loss: 1.909341  eta: 0h0m 0.005966  loss: 1.909261  eta: 0h0m   words/sec/thread: 288242  lr: 0.005885  loss: 1.908950  eta: 0h0m   words/sec/thread: 288263  lr: 0.005797  loss: 1.908204  eta: 0h0m   lr: 0.005737  loss: 1.907993  eta: 0h0m ad: 288301  lr: 0.005666  loss: 1.907793  eta: 0h0m 1.907748  eta: 0h0m 1.907533  eta: 0h0m h0m 9.0%  words/sec/thread: 288308  lr: 0.005513  loss: 1.907365  eta: 0h0m /thread: 288295  lr: 0.005446  loss: 1.907310  eta: 0h0m 7  eta: 0h0m ad: 288273  lr: 0.005304  loss: 1.907133  eta: 0h0m   words/sec/thread: 288261  lr: 0.005292  loss: 1.907049  eta: 0h0m   words/sec/thread: 288218  lr: 0.005235  loss: 1.906931  eta: 0h0m   words/sec/thread: 288168  lr: 0.005164  loss: 1.906659  eta: 0h0m ad: 288144  lr: 0.005097  loss: 1.906201  eta: 0h0m ad: 288105  lr: 0.005030  loss: 1.905971  eta: 0h0m   words/sec/thread: 288052  lr: 0.004908  loss: 1.905366  eta: 0h0m   words/sec/thread: 288058  lr: 0.004896  loss: 1.905386  eta: 0h0m ad: 288032  lr: 0.004822  loss: 1.905284  eta: 0h0m ad: 287989  lr: 0.004768  loss: 1.905046  eta: 0h0m   words/sec/thread: 287970  lr: 0.004760  loss: 1.905020  eta: 0h0m   words/sec/thread: 287968  lr: 0.004696  loss: 1.904828  eta: 0h0m thread: 287969  lr: 0.004612  loss: 1.904443  eta: 0h0m   words/sec/thread: 287955  lr: 0.004569  loss: 1.904160  eta: 0h0m 0.004553  loss: 1.903903  eta: 0h0m   words/sec/thread: 287938  lr: 0.004412  loss: 1.903417  eta: 0h0m 1.903338  eta: 0h0m a: 0h0m   words/sec/thread: 287901  lr: 0.004300  loss: 1.902969  eta: 0h0m   words/sec/thread: 287908  lr: 0.004223  loss: 1.902853  eta: 0h0m thread: 287913  lr: 0.004154  loss: 1.902963  eta: 0h0m lr: 0.004150  loss: 1.902989  eta: 0h0m ad: 287893  lr: 0.004081  loss: 1.903133  eta: 0h0m 0.004035  loss: 1.903319  eta: 0h0m   words/sec/thread: 287842  lr: 0.004000  loss: 1.903360  eta: 0h0m   words/sec/thread: 287828  lr: 0.003919  loss: 1.903231  eta: 0h0m   words/sec/thread: 287811  lr: 0.003889  loss: 1.902967  eta: 0h0m %  words/sec/thread: 287810  lr: 0.003879  loss: 1.902931  eta: 0h0m ad: 287796  lr: 0.003807  loss: 1.902705  eta: 0h0m   words/sec/thread: 287796  lr: 0.003743  loss: 1.902253  eta: 0h0m thread: 287774  lr: 0.003673  loss: 1.902265  eta: 0h0m a: 0h0m 287758  lr: 0.003603  loss: 1.902110  eta: 0h0m 0.003472  loss: 1.901700  eta: 0h0m "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003398  loss: 1.901586  eta: 0h0m \r",
      "Progress: 93.2%  words/sec/thread: 287663  lr: 0.003395  loss: 1.901584  eta: 0h0m \r",
      "Progress: 93.2%  words/sec/thread: 287663  lr: 0.003395  loss: 1.901587  eta: 0h0m \r",
      "Progress: 93.2%  words/sec/thread: 287663  lr: 0.003395  loss: 1.901589  eta: 0h0m \r",
      "Progress: 93.2%  words/sec/thread: 287662  lr: 0.003394  loss: 1.901587  eta: 0h0m \r",
      "Progress: 93.2%  words/sec/thread: 287662  lr: 0.003394  loss: 1.901586  eta: 0h0m \r",
      "Progress: 93.2%  words/sec/thread: 287662  lr: 0.003394  loss: 1.901582  eta: 0h0m \r",
      "Progress: 93.2%  words/sec/thread: 287662  lr: 0.003394  loss: 1.901580  eta: 0h0m \r",
      "Progress: 93.2%  words/sec/thread: 287662  lr: 0.003394  loss: 1.901584  eta: 0h0m \r",
      "Progress: 93.2%  words/sec/thread: 287662  lr: 0.003394  loss: 1.901580  eta: 0h0m \r",
      "Progress: 93.2%  words/sec/thread: 287662  lr: 0.003393  loss: 1.901572  eta: 0h0m \r",
      "Progress: 93.2%  words/sec/thread: 287660  lr: 0.003393  loss: 1.901572  eta: 0h0m \r",
      "Progress: 93.2%  words/sec/thread: 287660  lr: 0.003393  loss: 1.901564  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287651  lr: 0.003372  loss: 1.901559  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287652  lr: 0.003372  loss: 1.901562  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287651  lr: 0.003372  loss: 1.901554  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287651  lr: 0.003372  loss: 1.901556  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287650  lr: 0.003372  loss: 1.901552  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287650  lr: 0.003372  loss: 1.901547  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287650  lr: 0.003371  loss: 1.901539  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287650  lr: 0.003371  loss: 1.901531  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287650  lr: 0.003371  loss: 1.901522  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287650  lr: 0.003371  loss: 1.901528  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287651  lr: 0.003371  loss: 1.901527  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287651  lr: 0.003371  loss: 1.901536  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287652  lr: 0.003371  loss: 1.901535  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287651  lr: 0.003371  loss: 1.901532  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287651  lr: 0.003370  loss: 1.901530  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287651  lr: 0.003370  loss: 1.901527  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287652  lr: 0.003370  loss: 1.901525  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287653  lr: 0.003370  loss: 1.901527  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287651  lr: 0.003370  loss: 1.901523  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287651  lr: 0.003370  loss: 1.901529  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287652  lr: 0.003369  loss: 1.901527  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287651  lr: 0.003369  loss: 1.901527  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287647  lr: 0.003368  loss: 1.901525  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287647  lr: 0.003368  loss: 1.901528  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287646  lr: 0.003368  loss: 1.901525  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287647  lr: 0.003368  loss: 1.901522  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287647  lr: 0.003368  loss: 1.901514  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287647  lr: 0.003368  loss: 1.901512  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287647  lr: 0.003368  loss: 1.901512  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287647  lr: 0.003368  loss: 1.901512  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287645  lr: 0.003367  loss: 1.901508  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287646  lr: 0.003367  loss: 1.901505  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287645  lr: 0.003367  loss: 1.901499  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287645  lr: 0.003367  loss: 1.901498  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287644  lr: 0.003366  loss: 1.901502  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287644  lr: 0.003366  loss: 1.901504  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287644  lr: 0.003366  loss: 1.901502  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287645  lr: 0.003366  loss: 1.901503  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287645  lr: 0.003366  loss: 1.901500  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287646  lr: 0.003365  loss: 1.901497  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287646  lr: 0.003365  loss: 1.901498  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287646  lr: 0.003365  loss: 1.901504  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287647  lr: 0.003365  loss: 1.901500  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287647  lr: 0.003365  loss: 1.901494  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287648  lr: 0.003365  loss: 1.901488  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287647  lr: 0.003365  loss: 1.901490  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287647  lr: 0.003363  loss: 1.901489  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287646  lr: 0.003363  loss: 1.901487  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287646  lr: 0.003362  loss: 1.901479  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287645  lr: 0.003362  loss: 1.901482  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287645  lr: 0.003362  loss: 1.901480  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287646  lr: 0.003361  loss: 1.901476  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287644  lr: 0.003361  loss: 1.901470  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287645  lr: 0.003361  loss: 1.901464  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287645  lr: 0.003361  loss: 1.901455  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287645  lr: 0.003361  loss: 1.901453  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287645  lr: 0.003360  loss: 1.901457  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287644  lr: 0.003360  loss: 1.901452  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287641  lr: 0.003359  loss: 1.901448  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287642  lr: 0.003358  loss: 1.901441  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287642  lr: 0.003358  loss: 1.901438  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287643  lr: 0.003358  loss: 1.901442  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287643  lr: 0.003358  loss: 1.901436  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287643  lr: 0.003358  loss: 1.901434  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287643  lr: 0.003358  loss: 1.901423  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287643  lr: 0.003357  loss: 1.901420  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287643  lr: 0.003357  loss: 1.901410  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287642  lr: 0.003357  loss: 1.901405  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287643  lr: 0.003357  loss: 1.901402  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287643  lr: 0.003357  loss: 1.901403  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287643  lr: 0.003357  loss: 1.901408  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287643  lr: 0.003357  loss: 1.901405  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287643  lr: 0.003357  loss: 1.901405  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287643  lr: 0.003357  loss: 1.901400  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287644  lr: 0.003357  loss: 1.901400  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287644  lr: 0.003356  loss: 1.901399  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287643  lr: 0.003356  loss: 1.901380  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287643  lr: 0.003356  loss: 1.901349  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287637  lr: 0.003355  loss: 1.901323  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287636  lr: 0.003355  loss: 1.901301  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287636  lr: 0.003355  loss: 1.901301  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287636  lr: 0.003355  loss: 1.901299  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287635  lr: 0.003353  loss: 1.901308  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287636  lr: 0.003353  loss: 1.901307  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287636  lr: 0.003353  loss: 1.901308  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287634  lr: 0.003353  loss: 1.901313  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287634  lr: 0.003352  loss: 1.901316  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287634  lr: 0.003352  loss: 1.901322  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287634  lr: 0.003352  loss: 1.901324  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287634  lr: 0.003352  loss: 1.901331  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287634  lr: 0.003351  loss: 1.901325  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287634  lr: 0.003351  loss: 1.901326  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287633  lr: 0.003351  loss: 1.901319  eta: 0h0m \r",
      "Progress: 93.3%  words/sec/thread: 287631  lr:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100.0%  words/sec/thread: 287569  lr: 0.000000  loss: 1.895366  eta: 0h0m  words/sec/thread: 287579  lr: 0.003264  loss: 1.901560  eta: 0h0m 0.003168  loss: 1.901727  eta: 0h0m   words/sec/thread: 287498  lr: 0.003106  loss: 1.901904  eta: 0h0m   words/sec/thread: 287489  lr: 0.003038  loss: 1.901999  eta: 0h0m ad: 287430  lr: 0.002932  loss: 1.901759  eta: 0h0m thread: 287413  lr: 0.002876  loss: 1.901792  eta: 0h0m ad: 287392  lr: 0.002859  loss: 1.901695  eta: 0h0m ad: 287392  lr: 0.002792  loss: 1.901673  eta: 0h0m   words/sec/thread: 287373  lr: 0.002785  loss: 1.901708  eta: 0h0m ad: 287337  lr: 0.002721  loss: 1.901892  eta: 0h0m ad: 287300  lr: 0.002592  loss: 1.901672  eta: 0h0m 1.901633  eta: 0h0m   words/sec/thread: 287283  lr: 0.002514  loss: 1.901352  eta: 0h0m thread: 287268  lr: 0.002436  loss: 1.901234  eta: 0h0m 0.002392  loss: 1.901105  eta: 0h0m   words/sec/thread: 287266  lr: 0.002367  loss: 1.900847  eta: 0h0m   words/sec/thread: 287267  lr: 0.002288  loss: 1.900109  eta: 0h0m   words/sec/thread: 287247  lr: 0.002231  loss: 1.900061  eta: 0h0m   words/sec/thread: 287251  lr: 0.002221  loss: 1.900010  eta: 0h0m lr: 0.002154  loss: 1.899749  eta: 0h0m ad: 287283  lr: 0.002072  loss: 1.899369  eta: 0h0m ad: 287300  lr: 0.001993  loss: 1.899454  eta: 0h0m   words/sec/thread: 287309  lr: 0.001925  loss: 1.899420  eta: 0h0m ad: 287313  lr: 0.001858  loss: 1.899299  eta: 0h0m   words/sec/thread: 287321  lr: 0.001849  loss: 1.899291  eta: 0h0m ad: 287336  lr: 0.001776  loss: 1.899115  eta: 0h0m ss: 1.899003  eta: 0h0m gress: 96.7%  words/sec/thread: 287343  lr: 0.001643  loss: 1.898806  eta: 0h0m   words/sec/thread: 287327  lr: 0.001629  loss: 1.898654  eta: 0h0m   words/sec/thread: 287310  lr: 0.001552  loss: 1.898664  eta: 0h0m 0.001492  loss: 1.898379  eta: 0h0m   words/sec/thread: 287316  lr: 0.001480  loss: 1.898388  eta: 0h0m 8313  eta: 0h0m 0.001336  loss: 1.898204  eta: 0h0m s: 97.5%  words/sec/thread: 287346  lr: 0.001265  loss: 1.898097  eta: 0h0m   words/sec/thread: 287358  lr: 0.001190  loss: 1.897982  eta: 0h0m ad: 287356  lr: 0.001187  loss: 1.897962  eta: 0h0m 7.8%  words/sec/thread: 287393  lr: 0.001101  loss: 1.897814  eta: 0h0m oss: 1.897451  eta: 0h0m   words/sec/thread: 287419  lr: 0.000951  loss: 1.897360  eta: 0h0m ad: 287427  lr: 0.000884  loss: 1.897239  eta: 0h0m ad: 287438  lr: 0.000801  loss: 1.897066  eta: 0h0m a: 0h0m sec/thread: 287434  lr: 0.000722  loss: 1.896907  eta: 0h0m   words/sec/thread: 287446  lr: 0.000655  loss: 1.896819  eta: 0h0m  98.9%  words/sec/thread: 287465  lr: 0.000572  loss: 1.896450  eta: 0h0m   words/sec/thread: 287475  lr: 0.000513  loss: 1.896420  eta: 0h0m   words/sec/thread: 287469  lr: 0.000500  loss: 1.896352  eta: 0h0m ad: 287491  lr: 0.000420  loss: 1.896199  eta: 0h0m 0.000278  loss: 1.895750  eta: 0h0m ad: 287503  lr: 0.000212  loss: 1.895587  eta: 0h0m 1.895553  eta: 0h0m eta: 0h0m ad: 287553  lr: 0.000053  loss: 1.895396  eta: 0h0m \n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings pop\n",
    "! ./fasttext cbow -input lyrics_pop.txt -output model_lyrics_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 22M words\n",
      "Number of words:  33997\n",
      "Number of labels: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 40.4%  words/sec/thread: 300284  lr: 0.029815  loss: 2.069616  eta: 0h0m m   lr: 0.049699  loss: 3.160851  eta: 0h3m   loss: 2.906526  eta: 0h2m 0.9%  words/sec/thread: 60493  lr: 0.049527  loss: 2.845055  eta: 0h2m   loss: 2.760958  eta: 0h1m   lr: 0.049282  loss: 2.750509  eta: 0h1m hread: 120324  lr: 0.048799  loss: 2.589778  eta: 0h1m hread: 127099  lr: 0.048687  loss: 2.558353  eta: 0h1m hread: 129066  lr: 0.048655  loss: 2.548236  eta: 0h1m  loss: 2.503049  eta: 0h1m hread: 139799  lr: 0.048459  loss: 2.495817  eta: 0h1m 89  eta: 0h1m %  words/sec/thread: 146902  lr: 0.048309  loss: 2.460682  eta: 0h1m hread: 154832  lr: 0.048136  loss: 2.440478  eta: 0h0m   lr: 0.048069  loss: 2.432017  eta: 0h0m hread: 160221  lr: 0.048012  loss: 2.418918  eta: 0h0m 2.393095  eta: 0h0m 0h0m 181636  lr: 0.047428  loss: 2.355186  eta: 0h0m hread: 183594  lr: 0.047365  loss: 2.352024  eta: 0h0m hread: 184317  lr: 0.047339  loss: 2.350730  eta: 0h0m 0.047167  loss: 2.344465  eta: 0h0m 0m hread: 194258  lr: 0.046991  loss: 2.336175  eta: 0h0m   eta: 0h0m   loss: 2.331011  eta: 0h0m hread: 210549  lr: 0.046268  loss: 2.297192  eta: 0h0m hread: 211281  lr: 0.046233  loss: 2.294759  eta: 0h0m   words/sec/thread: 212514  lr: 0.046174  loss: 2.291413  eta: 0h0m 2.287357  eta: 0h0m s: 8.4%  words/sec/thread: 219384  lr: 0.045802  loss: 2.267089  eta: 0h0m c/thread: 221094  lr: 0.045710  loss: 2.263495  eta: 0h0m hread: 225087  lr: 0.045492  loss: 2.255525  eta: 0h0m hread: 225549  lr: 0.045463  loss: 2.254369  eta: 0h0m hread: 226561  lr: 0.045403  loss: 2.250932  eta: 0h0m hread: 227536  lr: 0.045343  loss: 2.248071  eta: 0h0m hread: 228690  lr: 0.045260  loss: 2.247206  eta: 0h0m hread: 229283  lr: 0.045210  loss: 2.244775  eta: 0h0m %  words/sec/thread: 229304  lr: 0.045207  loss: 2.244735  eta: 0h0m 9.8%  words/sec/thread: 231376  lr: 0.045078  loss: 2.235820  eta: 0h0m hread: 232103  lr: 0.045029  loss: 2.234646  eta: 0h0m   words/sec/thread: 234730  lr: 0.044849  loss: 2.225359  eta: 0h0m   lr: 0.044738  loss: 2.219720  eta: 0h0m   words/sec/thread: 237360  lr: 0.044625  loss: 2.219186  eta: 0h0m   words/sec/thread: 244541  lr: 0.043991  loss: 2.217509  eta: 0h0m   words/sec/thread: 245536  lr: 0.043904  loss: 2.214644  eta: 0h0m   words/sec/thread: 247157  lr: 0.043754  loss: 2.215122  eta: 0h0m 12.9%  words/sec/thread: 248900  lr: 0.043559  loss: 2.210234  eta: 0h0m   words/sec/thread: 249288  lr: 0.043519  loss: 2.209793  eta: 0h0m   words/sec/thread: 249530  lr: 0.043495  loss: 2.209037  eta: 0h0m ad: 250525  lr: 0.043399  loss: 2.207233  eta: 0h0m 9263  eta: 0h0m   loss: 2.198591  eta: 0h0m   words/sec/thread: 256818  lr: 0.042730  loss: 2.196657  eta: 0h0m   lr: 0.042644  loss: 2.194544  eta: 0h0m 0m   words/sec/thread: 259674  lr: 0.042353  loss: 2.189905  eta: 0h0m   loss: 2.190282  eta: 0h0m   words/sec/thread: 261240  lr: 0.042173  loss: 2.190049  eta: 0h0m   words/sec/thread: 261970  lr: 0.042083  loss: 2.185504  eta: 0h0m ad: 262248  lr: 0.042051  loss: 2.184095  eta: 0h0m 262582  lr: 0.041993  loss: 2.184083  eta: 0h0m m 0h0m   words/sec/thread: 265669  lr: 0.041534  loss: 2.179363  eta: 0h0m   eta: 0h0m %  words/sec/thread: 267041  lr: 0.041302  loss: 2.175301  eta: 0h0m   eta: 0h0m   lr: 0.041128  loss: 2.172284  eta: 0h0m 0h0m 268895  lr: 0.040984  loss: 2.168328  eta: 0h0m   words/sec/thread: 269437  lr: 0.040896  loss: 2.166726  eta: 0h0m /thread: 269645  lr: 0.040868  loss: 2.164687  eta: 0h0m /thread: 270667  lr: 0.040714  loss: 2.161088  eta: 0h0m 2.160817  eta: 0h0m   words/sec/thread: 272024  lr: 0.040486  loss: 2.158461  eta: 0h0m 0.040058  loss: 2.150126  eta: 0h0m   words/sec/thread: 274766  lr: 0.040013  loss: 2.149536  eta: 0h0m 274985  lr: 0.039944  loss: 2.148930  eta: 0h0m 20.3%  words/sec/thread: 275536  lr: 0.039830  loss: 2.146164  eta: 0h0m %  words/sec/thread: 276013  lr: 0.039702  loss: 2.144374  eta: 0h0m ad: 276548  lr: 0.039602  loss: 2.142043  eta: 0h0m   words/sec/thread: 277360  lr: 0.039453  loss: 2.140605  eta: 0h0m   words/sec/thread: 277521  lr: 0.039421  loss: 2.140125  eta: 0h0m 277815  lr: 0.039371  loss: 2.138273  eta: 0h0m %  words/sec/thread: 278087  lr: 0.039327  loss: 2.138177  eta: 0h0m   words/sec/thread: 278240  lr: 0.039298  loss: 2.136023  eta: 0h0m 278244  lr: 0.039291  loss: 2.136030  eta: 0h0m   loss: 2.136425  eta: 0h0m   words/sec/thread: 279556  lr: 0.038900  loss: 2.135276  eta: 0h0m 2.134057  eta: 0h0m   words/sec/thread: 280393  lr: 0.038642  loss: 2.133151  eta: 0h0m   eta: 0h0m   words/sec/thread: 280466  lr: 0.038565  loss: 2.132155  eta: 0h0m 2.131631  eta: 0h0m 23.1%  words/sec/thread: 280903  lr: 0.038449  loss: 2.131782  eta: 0h0m 23.2%  words/sec/thread: 281235  lr: 0.038385  loss: 2.132047  eta: 0h0m %  words/sec/thread: 281477  lr: 0.038323  loss: 2.132155  eta: 0h0m 0.038246  loss: 2.131585  eta: 0h0m   words/sec/thread: 282527  lr: 0.038010  loss: 2.130722  eta: 0h0m 283116  lr: 0.037834  loss: 2.130824  eta: 0h0m 0m 283427  lr: 0.037728  loss: 2.127282  eta: 0h0m m  lr: 0.037370  loss: 2.124365  eta: 0h0m 25.5%  words/sec/thread: 284515  lr: 0.037259  loss: 2.123072  eta: 0h0m 2.120180  eta: 0h0m 0.036962  loss: 2.120855  eta: 0h0m h0m   words/sec/thread: 286450  lr: 0.036414  loss: 2.117314  eta: 0h0m 0m 0.036295  loss: 2.116777  eta: 0h0m   words/sec/thread: 287020  lr: 0.036183  loss: 2.116593  eta: 0h0m   words/sec/thread: 287093  lr: 0.036155  loss: 2.116344  eta: 0h0m   eta: 0h0m 0h0m 2.114628  eta: 0h0m   words/sec/thread: 288319  lr: 0.035780  loss: 2.110540  eta: 0h0m h0m 0.035695  loss: 2.109445  eta: 0h0m   eta: 0h0m   words/sec/thread: 288863  lr: 0.035632  loss: 2.107667  eta: 0h0m 9%  words/sec/thread: 289056  lr: 0.035553  loss: 2.107223  eta: 0h0m   words/sec/thread: 289289  lr: 0.035464  loss: 2.106507  eta: 0h0m m ad: 289625  lr: 0.035370  loss: 2.105859  eta: 0h0m 0m   words/sec/thread: 289943  lr: 0.035257  loss: 2.103775  eta: 0h0m   words/sec/thread: 290340  lr: 0.035108  loss: 2.102969  eta: 0h0m   words/sec/thread: 290413  lr: 0.035053  loss: 2.102908  eta: 0h0m   words/sec/thread: 290447  lr: 0.035028  loss: 2.103000  eta: 0h0m 30.2%  words/sec/thread: 290615  lr: 0.034915  loss: 2.102878  eta: 0h0m m   eta: 0h0m   words/sec/thread: 291138  lr: 0.034591  loss: 2.101684  eta: 0h0m   words/sec/thread: 291208  lr: 0.034560  loss: 2.101296  eta: 0h0m   words/sec/thread: 291569  lr: 0.034427  loss: 2.099429  eta: 0h0m m ad: 291734  lr: 0.034349  loss: 2.099816  eta: 0h0m h0m   words/sec/thread: 292010  lr: 0.034228  loss: 2.096730  eta: 0h0m 0m 0.034024  loss: 2.096689  eta: 0h0m   loss: 2.096790  eta: 0h0m h0m ad: 292635  lr: 0.033936  loss: 2.095265  eta: 0h0m h0m h0m   words/sec/thread: 292896  lr: 0.033823  loss: 2.093469  eta: 0h0m h0m   words/sec/thread: 293455  lr: 0.033510  loss: 2.088289  eta: 0h0m   lr: 0.033156  loss: 2.087284  eta: 0h0m   words/sec/thread: 294514  lr: 0.033033  loss: 2.087108  eta: 0h0m   words/sec/thread: 294680  lr: 0.032973  loss: 2.086532  eta: 0h0m /thread: 295006  lr: 0.032836  loss: 2.083930  eta: 0h0m 0m 35.4%  words/sec/thread: 296043  lr: 0.032281  loss: 2.082344  eta: 0h0m   words/sec/thread: 296249  lr: 0.032195  loss: 2.082327  eta: 0h0m   words/sec/thread: 296305  lr: 0.032140  loss: 2.082014  eta: 0h0m   words/sec/thread: 296370  lr: 0.032087  loss: 2.081704  eta: 0h0m   words/sec/thread: 296692  lr: 0.031915  loss: 2.081107  eta: 0h0m ad: 296754  lr: 0.031880  loss: 2.081003  eta: 0h0m ad: 296969  lr: 0.031787  loss: 2.080468  eta: 0h0m   words/sec/thread: 297272  lr: 0.031638  loss: 2.078836  eta: 0h0m   words/sec/thread: 297339  lr: 0.031606  loss: 2.078650  eta: 0h0m m   words/sec/thread: 298156  lr: 0.031093  loss: 2.075042  eta: 0h0m ad: 298329  lr: 0.031007  loss: 2.073689  eta: 0h0m 298504  lr: 0.030927  loss: 2.072639  eta: 0h0m   words/sec/thread: 298656  lr: 0.030876  loss: 2.072528  eta: 0h0m ad: 299581  lr: 0.030353  loss: 2.069135  eta: 0h0m   eta: 0h0m   words/sec/thread: 299806  lr: 0.030211  loss: 2.067485  eta: 0h0m   words/sec/thread: 299911  lr: 0.030119  loss: 2.066955  eta: 0h0m 40.3%  words/sec/thread: 300232  lr: 0.029841  loss: 2.069814  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300335  lr: 0.029798  loss: 2.069618  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300333  lr: 0.029797  loss: 2.069607  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300334  lr: 0.029797  loss: 2.069592  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300335  lr: 0.029797  loss: 2.069584  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300334  lr: 0.029797  loss: 2.069584  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300334  lr: 0.029797  loss: 2.069580  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300335  lr: 0.029797  loss: 2.069569  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300335  lr: 0.029796  loss: 2.069562  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300336  lr: 0.029796  loss: 2.069546  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300335  lr: 0.029796  loss: 2.069545  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300335  lr: 0.029796  loss: 2.069559  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300334  lr: 0.029796  loss: 2.069546  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300335  lr: 0.029796  loss: 2.069540  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300336  lr: 0.029795  loss: 2.069545  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300335  lr: 0.029795  loss: 2.069533  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300337  lr: 0.029795  loss: 2.069541  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300337  lr: 0.029794  loss: 2.069550  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300338  lr: 0.029794  loss: 2.069555  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300336  lr: 0.029794  loss: 2.069542  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300337  lr: 0.029794  loss: 2.069534  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300338  lr: 0.029794  loss: 2.069534  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300334  lr: 0.029793  loss: 2.069531  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300335  lr: 0.029792  loss: 2.069516  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300334  lr: 0.029792  loss: 2.069492  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300334  lr: 0.029792  loss: 2.069477  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300335  lr: 0.029792  loss: 2.069455  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300334  lr: 0.029792  loss: 2.069421  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300333  lr: 0.029792  loss: 2.069435  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300333  lr: 0.029792  loss: 2.069446  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300335  lr: 0.029791  loss: 2.069462  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300336  lr: 0.029791  loss: 2.069477  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300337  lr: 0.029791  loss: 2.069510  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300336  lr: 0.029791  loss: 2.069525  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300337  lr: 0.029790  loss: 2.069505  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300337  lr: 0.029790  loss: 2.069511  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300337  lr: 0.029790  loss: 2.069513  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300338  lr: 0.029790  loss: 2.069552  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300338  lr: 0.029789  loss: 2.069558  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300338  lr: 0.029789  loss: 2.069576  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300337  lr: 0.029789  loss: 2.069595  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300337  lr: 0.029789  loss: 2.069592  eta: 0h0m \r",
      "Progress: 40.4%  words/sec/thread: 300336  lr: 0.029789  loss: 2.069607  eta: 0h0m "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 67.0%  words/sec/thread: 309370  lr: 0.016494  loss: 1.991949  eta: 0h0m   words/sec/thread: 300443  lr: 0.029719  loss: 2.069431  eta: 0h0m   words/sec/thread: 300532  lr: 0.029680  loss: 2.069059  eta: 0h0m   words/sec/thread: 300590  lr: 0.029651  loss: 2.068648  eta: 0h0m   loss: 2.067190  eta: 0h0m 5440  eta: 0h0m   words/sec/thread: 300982  lr: 0.029316  loss: 2.065063  eta: 0h0m h0m 2.064018  eta: 0h0m ad: 301349  lr: 0.028697  loss: 2.059445  eta: 0h0m 0.028641  loss: 2.058813  eta: 0h0m   words/sec/thread: 301410  lr: 0.028618  loss: 2.058542  eta: 0h0m   words/sec/thread: 301415  lr: 0.028588  loss: 2.058530  eta: 0h0m 0.028139  loss: 2.057700  eta: 0h0m 302167  lr: 0.028083  loss: 2.057727  eta: 0h0m ad: 302213  lr: 0.027977  loss: 2.056631  eta: 0h0m 44.1%  words/sec/thread: 302247  lr: 0.027931  loss: 2.056175  eta: 0h0m 7896  loss: 2.055769  eta: 0h0m ess: 44.8%  words/sec/thread: 302376  lr: 0.027599  loss: 2.053337  eta: 0h0m s/sec/thread: 302422  lr: 0.027566  loss: 2.053328  eta: 0h0m   words/sec/thread: 302493  lr: 0.027498  loss: 2.052976  eta: 0h0m   words/sec/thread: 302675  lr: 0.027379  loss: 2.052493  eta: 0h0m /thread: 302699  lr: 0.027348  loss: 2.052495  eta: 0h0m .4%  words/sec/thread: 302722  lr: 0.027316  loss: 2.052346  eta: 0h0m   words/sec/thread: 302763  lr: 0.027259  loss: 2.051959  eta: 0h0m 0.027113  loss: 2.051080  eta: 0h0m read: 303002  lr: 0.027031  loss: 2.050220  eta: 0h0m   words/sec/thread: 303033  lr: 0.026948  loss: 2.050104  eta: 0h0m   eta: 0h0m   words/sec/thread: 303155  lr: 0.026744  loss: 2.049367  eta: 0h0m   words/sec/thread: 303190  lr: 0.026718  loss: 2.049182  eta: 0h0m 0.026601  loss: 2.048609  eta: 0h0m gress: 47.0%  words/sec/thread: 303306  lr: 0.026506  loss: 2.048646  eta: 0h0m  lr: 0.026390  loss: 2.047609  eta: 0h0m 0.026194  loss: 2.047264  eta: 0h0m ad: 303724  lr: 0.026103  loss: 2.045903  eta: 0h0m   words/sec/thread: 303841  lr: 0.026010  loss: 2.045208  eta: 0h0m 0h0m   words/sec/thread: 304262  lr: 0.025739  loss: 2.042043  eta: 0h0m ead: 304346  lr: 0.025689  loss: 2.041884  eta: 0h0m   words/sec/thread: 304399  lr: 0.025648  loss: 2.041665  eta: 0h0m   words/sec/thread: 304494  lr: 0.025550  loss: 2.040924  eta: 0h0m 0m 0.025411  loss: 2.040946  eta: 0h0m   eta: 0h0m   words/sec/thread: 304722  lr: 0.025018  loss: 2.039965  eta: 0h0m 50.1%  words/sec/thread: 304737  lr: 0.024938  loss: 2.039491  eta: 0h0m   words/sec/thread: 304770  lr: 0.024882  loss: 2.039095  eta: 0h0m 4829  loss: 2.038443  eta: 0h0m   words/sec/thread: 304785  lr: 0.024726  loss: 2.037907  eta: 0h0m 0.8%  words/sec/thread: 304865  lr: 0.024590  loss: 2.037136  eta: 0h0m 2.034351  eta: 0h0m   words/sec/thread: 305074  lr: 0.024374  loss: 2.033670  eta: 0h0m 4210  loss: 2.033219  eta: 0h0m   words/sec/thread: 305221  lr: 0.024168  loss: 2.032727  eta: 0h0m   words/sec/thread: 305265  lr: 0.024107  loss: 2.032668  eta: 0h0m   words/sec/thread: 305273  lr: 0.024082  loss: 2.032542  eta: 0h0m rds/sec/thread: 305363  lr: 0.023961  loss: 2.031875  eta: 0h0m 305645  lr: 0.023570  loss: 2.031638  eta: 0h0m 0.023533  loss: 2.031040  eta: 0h0m 0h0m /thread: 305739  lr: 0.023475  loss: 2.030466  eta: 0h0m   words/sec/thread: 305759  lr: 0.023462  loss: 2.030025  eta: 0h0m ad: 306120  lr: 0.023162  loss: 2.028815  eta: 0h0m h0m %  words/sec/thread: 306261  lr: 0.022962  loss: 2.027344  eta: 0h0m   words/sec/thread: 306300  lr: 0.022923  loss: 2.027247  eta: 0h0m   words/sec/thread: 306410  lr: 0.022769  loss: 2.026893  eta: 0h0m   words/sec/thread: 306575  lr: 0.022560  loss: 2.026850  eta: 0h0m 2.026271  eta: 0h0m h0m rds/sec/thread: 306665  lr: 0.022373  loss: 2.026045  eta: 0h0m   eta: 0h0m   words/sec/thread: 306740  lr: 0.022273  loss: 2.024825  eta: 0h0m   words/sec/thread: 306848  lr: 0.022119  loss: 2.023935  eta: 0h0m ad: 306900  lr: 0.021998  loss: 2.022715  eta: 0h0m   words/sec/thread: 306921  lr: 0.021952  loss: 2.022379  eta: 0h0m ad: 306972  lr: 0.021765  loss: 2.021441  eta: 0h0m   words/sec/thread: 307009  lr: 0.021708  loss: 2.021345  eta: 0h0m   words/sec/thread: 307086  lr: 0.021505  loss: 2.020678  eta: 0h0m %  words/sec/thread: 307108  lr: 0.021364  loss: 2.020071  eta: 0h0m   words/sec/thread: 307189  lr: 0.021225  loss: 2.019540  eta: 0h0m   words/sec/thread: 307354  lr: 0.021002  loss: 2.017624  eta: 0h0m   words/sec/thread: 307342  lr: 0.020992  loss: 2.017498  eta: 0h0m ad: 307416  lr: 0.020952  loss: 2.017465  eta: 0h0m ad: 307462  lr: 0.020919  loss: 2.017028  eta: 0h0m m   words/sec/thread: 307555  lr: 0.020794  loss: 2.016553  eta: 0h0m ad: 307560  lr: 0.020772  loss: 2.016418  eta: 0h0m ad: 307628  lr: 0.020634  loss: 2.015196  eta: 0h0m ad: 307949  lr: 0.020192  loss: 2.013353  eta: 0h0m ad: 307996  lr: 0.020139  loss: 2.013016  eta: 0h0m   words/sec/thread: 308019  lr: 0.020087  loss: 2.012805  eta: 0h0m   words/sec/thread: 308066  lr: 0.020019  loss: 2.012373  eta: 0h0m %  words/sec/thread: 308090  lr: 0.019922  loss: 2.011852  eta: 0h0m 60.5%  words/sec/thread: 308168  lr: 0.019750  loss: 2.010808  eta: 0h0m   words/sec/thread: 308171  lr: 0.019732  loss: 2.010532  eta: 0h0m   words/sec/thread: 308208  lr: 0.019658  loss: 2.010095  eta: 0h0m   words/sec/thread: 308233  lr: 0.019596  loss: 2.009719  eta: 0h0m ad: 308268  lr: 0.019500  loss: 2.009159  eta: 0h0m   words/sec/thread: 308295  lr: 0.019465  loss: 2.009029  eta: 0h0m   words/sec/thread: 308319  lr: 0.019438  loss: 2.008645  eta: 0h0m   words/sec/thread: 308373  lr: 0.019360  loss: 2.008148  eta: 0h0m   words/sec/thread: 308372  lr: 0.019312  loss: 2.007874  eta: 0h0m ad: 308398  lr: 0.019186  loss: 2.006813  eta: 0h0m 61.8%  words/sec/thread: 308465  lr: 0.019113  loss: 2.006340  eta: 0h0m 0.019090  loss: 2.005838  eta: 0h0m   words/sec/thread: 308462  lr: 0.018951  loss: 2.005715  eta: 0h0m   words/sec/thread: 308503  lr: 0.018879  loss: 2.005628  eta: 0h0m   words/sec/thread: 308525  lr: 0.018848  loss: 2.005445  eta: 0h0m   words/sec/thread: 308583  lr: 0.018747  loss: 2.004813  eta: 0h0m   words/sec/thread: 308598  lr: 0.018684  loss: 2.004285  eta: 0h0m   words/sec/thread: 308630  lr: 0.018629  loss: 2.003821  eta: 0h0m   words/sec/thread: 308738  lr: 0.018508  loss: 2.002720  eta: 0h0m ad: 308776  lr: 0.018479  loss: 2.002007  eta: 0h0m   words/sec/thread: 308831  lr: 0.018381  loss: 2.001140  eta: 0h0m 0.018356  loss: 2.000922  eta: 0h0m  2.000127  eta: 0h0m ad: 308885  lr: 0.018264  loss: 1.999897  eta: 0h0m ad: 308895  lr: 0.018136  loss: 1.999431  eta: 0h0m ad: 308879  lr: 0.018102  loss: 1.999312  eta: 0h0m   words/sec/thread: 308888  lr: 0.018059  loss: 1.999229  eta: 0h0m ad: 308931  lr: 0.017986  loss: 1.998857  eta: 0h0m   words/sec/thread: 308926  lr: 0.017969  loss: 1.998513  eta: 0h0m ad: 308948  lr: 0.017906  loss: 1.998350  eta: 0h0m 0.017866  loss: 1.998179  eta: 0h0m   words/sec/thread: 308960  lr: 0.017791  loss: 1.998167  eta: 0h0m ad: 308958  lr: 0.017771  loss: 1.998022  eta: 0h0m   words/sec/thread: 308977  lr: 0.017740  loss: 1.997928  eta: 0h0m .5%  words/sec/thread: 308980  lr: 0.017727  loss: 1.997730  eta: 0h0m   lr: 0.017653  loss: 1.997292  eta: 0h0m ad: 309047  lr: 0.017621  loss: 1.997110  eta: 0h0m   words/sec/thread: 309067  lr: 0.017501  loss: 1.996541  eta: 0h0m oss: 1.996203  eta: 0h0m 1.995908  eta: 0h0m   words/sec/thread: 309146  lr: 0.017340  loss: 1.995237  eta: 0h0m ad: 309170  lr: 0.017315  loss: 1.995000  eta: 0h0m   lr: 0.017277  loss: 1.994837  eta: 0h0m loss: 1.994790  eta: 0h0m 65.5%  words/sec/thread: 309185  lr: 0.017231  loss: 1.994863  eta: 0h0m /thread: 309187  lr: 0.017192  loss: 1.994873  eta: 0h0m h0m   words/sec/thread: 309229  lr: 0.017024  loss: 1.994285  eta: 0h0m   words/sec/thread: 309242  lr: 0.016926  loss: 1.994184  eta: 0h0m h0m 0.016844  loss: 1.993608  eta: 0h0m   words/sec/thread: 309247  lr: 0.016806  loss: 1.993459  eta: 0h0m 0.016777  loss: 1.993247  eta: 0h0m 0h0m   words/sec/thread: 309298  lr: 0.016677  loss: 1.992970  eta: 0h0m   words/sec/thread: 309296  lr: 0.016650  loss: 1.992793  eta: 0h0m   words/sec/thread: 309318  lr: 0.016585  loss: 1.992455  eta: 0h0m   words/sec/thread: 309356  lr: 0.016529  loss: 1.992197  eta: 0h0m "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 90.2%  words/sec/thread: 311205  lr: 0.004900  loss: 1.951695  eta: 0h0m   words/sec/thread: 309434  lr: 0.016413  loss: 1.991734  eta: 0h0m ad: 309442  lr: 0.016377  loss: 1.991649  eta: 0h0m   words/sec/thread: 309573  lr: 0.016248  loss: 1.991548  eta: 0h0m 0.016223  loss: 1.991288  eta: 0h0m 1.990965  eta: 0h0m ad: 309717  lr: 0.016131  loss: 1.990813  eta: 0h0m   words/sec/thread: 309754  lr: 0.016087  loss: 1.990520  eta: 0h0m 1.990336  eta: 0h0m 0.015994  loss: 1.990606  eta: 0h0m   words/sec/thread: 309883  lr: 0.015889  loss: 1.990425  eta: 0h0m   words/sec/thread: 309888  lr: 0.015826  loss: 1.990164  eta: 0h0m   words/sec/thread: 309852  lr: 0.015713  loss: 1.989577  eta: 0h0m ad: 309831  lr: 0.015618  loss: 1.989069  eta: 0h0m   words/sec/thread: 309751  lr: 0.015472  loss: 1.988670  eta: 0h0m   words/sec/thread: 309721  lr: 0.015447  loss: 1.988567  eta: 0h0m ad: 309675  lr: 0.015338  loss: 1.987903  eta: 0h0m   words/sec/thread: 309600  lr: 0.015005  loss: 1.986753  eta: 0h0m /thread: 309660  lr: 0.014805  loss: 1.985500  eta: 0h0m 1.984840  eta: 0h0m   words/sec/thread: 309829  lr: 0.014574  loss: 1.984390  eta: 0h0m   words/sec/thread: 309821  lr: 0.014567  loss: 1.984281  eta: 0h0m   words/sec/thread: 309856  lr: 0.014505  loss: 1.983899  eta: 0h0m ad: 309891  lr: 0.014452  loss: 1.983667  eta: 0h0m   words/sec/thread: 309939  lr: 0.014324  loss: 1.983138  eta: 0h0m 1.983081  eta: 0h0m   words/sec/thread: 309927  lr: 0.014246  loss: 1.982959  eta: 0h0m   words/sec/thread: 309944  lr: 0.014205  loss: 1.982816  eta: 0h0m %  words/sec/thread: 309939  lr: 0.014196  loss: 1.982774  eta: 0h0m 309967  lr: 0.014090  loss: 1.982689  eta: 0h0m   words/sec/thread: 309966  lr: 0.014074  loss: 1.982746  eta: 0h0m   words/sec/thread: 309996  lr: 0.014007  loss: 1.982734  eta: 0h0m ad: 310013  lr: 0.013957  loss: 1.982449  eta: 0h0m 0.013880  loss: 1.982522  eta: 0h0m   words/sec/thread: 310066  lr: 0.013764  loss: 1.982722  eta: 0h0m 0.013740  loss: 1.982702  eta: 0h0m 0.013619  loss: 1.982652  eta: 0h0m   words/sec/thread: 310211  lr: 0.013531  loss: 1.982323  eta: 0h0m 0.013516  loss: 1.982246  eta: 0h0m loss: 1.981879  eta: 0h0m 0.013141  loss: 1.981659  eta: 0h0m   words/sec/thread: 310358  lr: 0.013064  loss: 1.981506  eta: 0h0m 0.013001  loss: 1.981088  eta: 0h0m 1.980749  eta: 0h0m 1.980736  eta: 0h0m .3%  words/sec/thread: 310451  lr: 0.012827  loss: 1.980659  eta: 0h0m   words/sec/thread: 310472  lr: 0.012692  loss: 1.980785  eta: 0h0m 0.012643  loss: 1.980565  eta: 0h0m   words/sec/thread: 310493  lr: 0.012585  loss: 1.980359  eta: 0h0m ad: 310541  lr: 0.012523  loss: 1.980093  eta: 0h0m   words/sec/thread: 310578  lr: 0.012491  loss: 1.979969  eta: 0h0m   words/sec/thread: 310588  lr: 0.012429  loss: 1.979756  eta: 0h0m ad: 310643  lr: 0.012218  loss: 1.979114  eta: 0h0m ad: 310622  lr: 0.012191  loss: 1.979140  eta: 0h0m ad: 310669  lr: 0.012132  loss: 1.979196  eta: 0h0m ad: 310704  lr: 0.012091  loss: 1.979029  eta: 0h0m   words/sec/thread: 310745  lr: 0.012038  loss: 1.978956  eta: 0h0m   words/sec/thread: 310758  lr: 0.012002  loss: 1.978667  eta: 0h0m   words/sec/thread: 310762  lr: 0.011951  loss: 1.978524  eta: 0h0m   words/sec/thread: 310760  lr: 0.011928  loss: 1.978378  eta: 0h0m   words/sec/thread: 310765  lr: 0.011816  loss: 1.977970  eta: 0h0m 5%  words/sec/thread: 310783  lr: 0.011755  loss: 1.977804  eta: 0h0m ad: 310783  lr: 0.011730  loss: 1.977698  eta: 0h0m 1.977677  eta: 0h0m 0.011634  loss: 1.977678  eta: 0h0m   words/sec/thread: 310860  lr: 0.011586  loss: 1.977522  eta: 0h0m   loss: 1.977020  eta: 0h0m   words/sec/thread: 310924  lr: 0.011407  loss: 1.976771  eta: 0h0m 0.011309  loss: 1.976129  eta: 0h0m   words/sec/thread: 310998  lr: 0.011229  loss: 1.975929  eta: 0h0m gress: 77.6%  words/sec/thread: 311018  lr: 0.011188  loss: 1.975470  eta: 0h0m 7.8%  words/sec/thread: 311060  lr: 0.011124  loss: 1.974988  eta: 0h0m h0m 0.011054  loss: 1.974463  eta: 0h0m   words/sec/thread: 311085  lr: 0.011000  loss: 1.974173  eta: 0h0m ad: 311110  lr: 0.010975  loss: 1.973938  eta: 0h0m   words/sec/thread: 311133  lr: 0.010933  loss: 1.973500  eta: 0h0m   words/sec/thread: 311208  lr: 0.010851  loss: 1.973069  eta: 0h0m ad: 311272  lr: 0.010757  loss: 1.972347  eta: 0h0m   words/sec/thread: 311326  lr: 0.010660  loss: 1.971757  eta: 0h0m   words/sec/thread: 311393  lr: 0.010537  loss: 1.970781  eta: 0h0m   words/sec/thread: 311402  lr: 0.010502  loss: 1.970435  eta: 0h0m   words/sec/thread: 311426  lr: 0.010411  loss: 1.969996  eta: 0h0m 0.010362  loss: 1.969763  eta: 0h0m 79.7%  words/sec/thread: 311378  lr: 0.010149  loss: 1.969820  eta: 0h0m 1.969721  eta: 0h0m /thread: 311315  lr: 0.009930  loss: 1.969748  eta: 0h0m   words/sec/thread: 311312  lr: 0.009875  loss: 1.969619  eta: 0h0m   words/sec/thread: 311389  lr: 0.009683  loss: 1.969612  eta: 0h0m   loss: 1.969524  eta: 0h0m   words/sec/thread: 311417  lr: 0.009502  loss: 1.969205  eta: 0h0m   words/sec/thread: 311411  lr: 0.009451  loss: 1.968922  eta: 0h0m   words/sec/thread: 311398  lr: 0.009398  loss: 1.968639  eta: 0h0m   words/sec/thread: 311392  lr: 0.009219  loss: 1.967461  eta: 0h0m   words/sec/thread: 311307  lr: 0.009079  loss: 1.967077  eta: 0h0m h0m lr: 0.009033  loss: 1.967019  eta: 0h0m   words/sec/thread: 311312  lr: 0.008968  loss: 1.966785  eta: 0h0m ad: 311305  lr: 0.008936  loss: 1.966318  eta: 0h0m   words/sec/thread: 311313  lr: 0.008921  loss: 1.966014  eta: 0h0m ad: 311283  lr: 0.008852  loss: 1.965567  eta: 0h0m   words/sec/thread: 311248  lr: 0.008688  loss: 1.964994  eta: 0h0m   words/sec/thread: 311281  lr: 0.008543  loss: 1.964580  eta: 0h0m 4126  eta: 0h0m ad: 311291  lr: 0.008444  loss: 1.963820  eta: 0h0m   words/sec/thread: 311319  lr: 0.008377  loss: 1.963431  eta: 0h0m 1.962749  eta: 0h0m   words/sec/thread: 311234  lr: 0.008039  loss: 1.962615  eta: 0h0m 0h0m   words/sec/thread: 311222  lr: 0.007932  loss: 1.962240  eta: 0h0m ad: 311223  lr: 0.007885  loss: 1.962015  eta: 0h0m   words/sec/thread: 311219  lr: 0.007878  loss: 1.961868  eta: 0h0m /thread: 311226  lr: 0.007764  loss: 1.961457  eta: 0h0m   words/sec/thread: 311236  lr: 0.007610  loss: 1.961041  eta: 0h0m 0h0m 0.007334  loss: 1.959963  eta: 0h0m 3%  words/sec/thread: 311153  lr: 0.007327  loss: 1.959875  eta: 0h0m   words/sec/thread: 311146  lr: 0.007268  loss: 1.959584  eta: 0h0m   words/sec/thread: 311090  lr: 0.007207  loss: 1.959394  eta: 0h0m 0.007131  loss: 1.958922  eta: 0h0m   words/sec/thread: 311075  lr: 0.007074  loss: 1.958822  eta: 0h0m 0.006961  loss: 1.958412  eta: 0h0m   words/sec/thread: 311089  lr: 0.006910  loss: 1.958001  eta: 0h0m ad: 311105  lr: 0.006865  loss: 1.957719  eta: 0h0m   words/sec/thread: 311085  lr: 0.006812  loss: 1.957411  eta: 0h0m   words/sec/thread: 311095  lr: 0.006671  loss: 1.956515  eta: 0h0m   words/sec/thread: 311102  lr: 0.006660  loss: 1.956373  eta: 0h0m ad: 311059  lr: 0.006525  loss: 1.956016  eta: 0h0m ad: 311050  lr: 0.006517  loss: 1.955928  eta: 0h0m   words/sec/thread: 311111  lr: 0.006397  loss: 1.955464  eta: 0h0m 0.006358  loss: 1.955388  eta: 0h0m   words/sec/thread: 311122  lr: 0.006305  loss: 1.955206  eta: 0h0m   words/sec/thread: 311127  lr: 0.006159  loss: 1.955079  eta: 0h0m   words/sec/thread: 311136  lr: 0.006106  loss: 1.954871  eta: 0h0m   words/sec/thread: 311138  lr: 0.005965  loss: 1.954518  eta: 0h0m   words/sec/thread: 311141  lr: 0.005854  loss: 1.954273  eta: 0h0m   words/sec/thread: 311152  lr: 0.005785  loss: 1.953969  eta: 0h0m 0.005766  loss: 1.953856  eta: 0h0m   words/sec/thread: 311158  lr: 0.005691  loss: 1.953543  eta: 0h0m ad: 311193  lr: 0.005648  loss: 1.953437  eta: 0h0m 8.8%  words/sec/thread: 311184  lr: 0.005605  loss: 1.953296  eta: 0h0m   words/sec/thread: 311191  lr: 0.005556  loss: 1.952959  eta: 0h0m   words/sec/thread: 311151  lr: 0.005316  loss: 1.952954  eta: 0h0m   words/sec/thread: 311131  lr: 0.005261  loss: 1.952900  eta: 0h0m 0.005148  loss: 1.952341  eta: 0h0m ad: 311185  lr: 0.005056  loss: 1.951929  eta: 0h0m   words/sec/thread: 311202  lr: 0.004987  loss: 1.951753  eta: 0h0m 0.1%  words/sec/thread: 311195  lr: 0.004956  loss: 1.951839  eta: 0h0m "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100.0%  words/sec/thread: 312334  lr: 0.000000  loss: 1.939480  eta: 0h0m  words/sec/thread: 311261  lr: 0.004838  loss: 1.951455  eta: 0h0m   words/sec/thread: 311268  lr: 0.004832  loss: 1.951380  eta: 0h0m thread: 311326  lr: 0.004764  loss: 1.951257  eta: 0h0m ad: 311328  lr: 0.004709  loss: 1.950978  eta: 0h0m   words/sec/thread: 311347  lr: 0.004595  loss: 1.950639  eta: 0h0m  1.950390  eta: 0h0m 1.4%  words/sec/thread: 311424  lr: 0.004284  loss: 1.949726  eta: 0h0m thread: 311425  lr: 0.004264  loss: 1.949452  eta: 0h0m ad: 311464  lr: 0.004197  loss: 1.949258  eta: 0h0m ad: 311484  lr: 0.004140  loss: 1.949018  eta: 0h0m   words/sec/thread: 311486  lr: 0.004133  loss: 1.948943  eta: 0h0m thread: 311515  lr: 0.004071  loss: 1.948986  eta: 0h0m   words/sec/thread: 311522  lr: 0.004016  loss: 1.948842  eta: 0h0m   words/sec/thread: 311524  lr: 0.004007  loss: 1.948870  eta: 0h0m   words/sec/thread: 311552  lr: 0.003937  loss: 1.948857  eta: 0h0m ad: 311597  lr: 0.003879  loss: 1.948687  eta: 0h0m   words/sec/thread: 311607  lr: 0.003825  loss: 1.948342  eta: 0h0m  0.003747  loss: 1.948002  eta: 0h0m 0.003686  loss: 1.947618  eta: 0h0m s: 92.8%  words/sec/thread: 311729  lr: 0.003621  loss: 1.947344  eta: 0h0m ad: 311754  lr: 0.003559  loss: 1.947096  eta: 0h0m   words/sec/thread: 311753  lr: 0.003550  loss: 1.947044  eta: 0h0m   eta: 0h0m gress: 93.2%  words/sec/thread: 311807  lr: 0.003419  loss: 1.946415  eta: 0h0m  lr: 0.003366  loss: 1.946082  eta: 0h0m ta: 0h0m ad: 311850  lr: 0.003296  loss: 1.945935  eta: 0h0m rds/sec/thread: 311864  lr: 0.003243  loss: 1.945834  eta: 0h0m   lr: 0.003235  loss: 1.945779  eta: 0h0m ad: 311898  lr: 0.003172  loss: 1.945536  eta: 0h0m ad: 311925  lr: 0.003102  loss: 1.945224  eta: 0h0m   words/sec/thread: 311982  lr: 0.002966  loss: 1.944802  eta: 0h0m 0.002940  loss: 1.944675  eta: 0h0m /thread: 311998  lr: 0.002932  loss: 1.944633  eta: 0h0m   words/sec/thread: 312018  lr: 0.002823  loss: 1.944538  eta: 0h0m   words/sec/thread: 312094  lr: 0.002605  loss: 1.944625  eta: 0h0m ad: 312094  lr: 0.002416  loss: 1.944615  eta: 0h0m 5.4%  words/sec/thread: 312116  lr: 0.002300  loss: 1.944246  eta: 0h0m   words/sec/thread: 312136  lr: 0.002223  loss: 1.944262  eta: 0h0m   words/sec/thread: 312131  lr: 0.002165  loss: 1.944241  eta: 0h0m   words/sec/thread: 312123  lr: 0.002139  loss: 1.944334  eta: 0h0m ad: 312116  lr: 0.002104  loss: 1.944340  eta: 0h0m 6.1%  words/sec/thread: 312147  lr: 0.001974  loss: 1.944180  eta: 0h0m 0.001920  loss: 1.944101  eta: 0h0m   words/sec/thread: 312110  lr: 0.001875  loss: 1.943920  eta: 0h0m 1.943654  eta: 0h0m   words/sec/thread: 312134  lr: 0.001712  loss: 1.943320  eta: 0h0m ad: 312153  lr: 0.001666  loss: 1.943088  eta: 0h0m 0.001625  loss: 1.942953  eta: 0h0m 96.8%  words/sec/thread: 312122  lr: 0.001583  loss: 1.943004  eta: 0h0m ad: 312152  lr: 0.001497  loss: 1.943069  eta: 0h0m gress: 97.4%  words/sec/thread: 312178  lr: 0.001319  loss: 1.942337  eta: 0h0m   words/sec/thread: 312197  lr: 0.001277  loss: 1.942158  eta: 0h0m   words/sec/thread: 312197  lr: 0.001268  loss: 1.942074  eta: 0h0m ad: 312249  lr: 0.001089  loss: 1.942175  eta: 0h0m   words/sec/thread: 312246  lr: 0.001001  loss: 1.942397  eta: 0h0m   words/sec/thread: 312271  lr: 0.000804  loss: 1.941812  eta: 0h0m   words/sec/thread: 312290  lr: 0.000743  loss: 1.941649  eta: 0h0m   words/sec/thread: 312271  lr: 0.000690  loss: 1.941549  eta: 0h0m   words/sec/thread: 312273  lr: 0.000665  loss: 1.941432  eta: 0h0m 1.941294  eta: 0h0m 0.000545  loss: 1.940977  eta: 0h0m ad: 312342  lr: 0.000467  loss: 1.940883  eta: 0h0m   words/sec/thread: 312327  lr: 0.000440  loss: 1.940623  eta: 0h0m ad: 312314  lr: 0.000367  loss: 1.940390  eta: 0h0m 0351  loss: 1.940258  eta: 0h0m   words/sec/thread: 312311  lr: 0.000222  loss: 1.940030  eta: 0h0m 1.939889  eta: 0h0m  lr: 0.000072  loss: 1.939631  eta: 0h0m \n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings rock\n",
    "! ./fasttext cbow -input lyrics_rock.txt -output model_lyrics_rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "def load_embeddings(file_name):\n",
    "    with codecs.open(file_name, 'r', 'utf-8') as f_in:\n",
    "        lines = f_in.readlines()\n",
    "        lines = lines[1:]\n",
    "        vocabulary, wv = zip(*[line.strip().split(' ', 1) for line in lines])\n",
    "    wv = np.loadtxt(wv)\n",
    "    return wv, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings_pop, vocabulary_pop = load_embeddings('model_lyrics_pop.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings_rock, vocabulary_rock = load_embeddings('model_lyrics_rock.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_pop = list(vocabulary_pop)\n",
    "voc_rock = list(vocabulary_rock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33997"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voc_rock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29549\n"
     ]
    }
   ],
   "source": [
    "print(len(voc_pop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['29',\n",
       " 'designer',\n",
       " 'late',\n",
       " 'clicks',\n",
       " 'nursed',\n",
       " 'desmond',\n",
       " '1998',\n",
       " 'mangled',\n",
       " 'lecture',\n",
       " 'greg']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words = set(voc_pop).intersection(set(voc_rock))\n",
    "print(len(common_words))\n",
    "common_words = list(common_words)\n",
    "common_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in voc_rock:\n",
    "    if re.match('[a-z]+[A-Z]+[a-z]+',w):\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7428677789434499\n",
      "0.6456746183486778\n"
     ]
    }
   ],
   "source": [
    "#Percentage of common words \n",
    "print(len(common_words)/len(voc_pop))\n",
    "print(len(common_words)/len(voc_rock))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "Source : https://www.kaggle.com/adamschroeder/countvectorizer-tfidfvectorizer-predict-comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_pop = list(lyrics_df[lyrics_df['genre'] == 'pop']['lyrics'])\n",
    "corpus_pop = [x.replace('\\n', ' ').replace(\"'\", ' ').lower() for x in corpus_pop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_rock = list(lyrics_df[lyrics_df['genre'] == 'rock']['lyrics'])\n",
    "corpus_rock = [x.replace('\\n', ' ').replace(\"'\", ' ').lower() for x in corpus_rock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(corpus, max_freq, min_freq):\n",
    "    tf = TfidfVectorizer(stop_words='english', max_df=max_freq, min_df=min_freq)\n",
    "    X = tf.fit(corpus)\n",
    "    X_transformed = X.transform(corpus)\n",
    "    # find maximum value for each of the features over all of dataset:\n",
    "    max_val = X_transformed.max(axis=0).toarray().ravel()\n",
    "\n",
    "    feature_names = np.array(tf.get_feature_names())\n",
    "    sorted_by_idf = np.argsort(tf.idf_)\n",
    "\n",
    "    #sort weights from smallest to biggest and extract their indices \n",
    "    sort_by_tfidf = max_val.argsort()\n",
    "    return feature_names[sort_by_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with lowest tfidf:\n",
      "['youven' 'snsd' 'naegenaege' 'gakka' 'soljikan' 'jeulgyeobwa' 'tteugeopke'\n",
      " 'kkeuteopneun' '2pm' 'eumeul']\n",
      "\n",
      "Features with highest tfidf: \n",
      "['intrumental' 'instrumental' 'stand' 'coming' 'turn' 'silhouette'\n",
      " 'stingray' 'embed' 'lyrics' 'hey']\n"
     ]
    }
   ],
   "source": [
    "tfidf_pop = get_tfidf(corpus_pop, 1.0, 0.0)\n",
    "print(\"Features with lowest tfidf:\\n{}\".format(tfidf_pop[:10]))\n",
    "\n",
    "print(\"\\nFeatures with highest tfidf: \\n{}\".format(tfidf_pop[-10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with lowest tfidf:\n",
      "['heighho' 'aalley' 'greivin' 'chinchara' 'saftey' 'yayara' 'yeshot'\n",
      " 'acelandine' 'hivoltage' 'scoundel']\n",
      "\n",
      "Features with highest tfidf: \n",
      "['work' 'paid' 'awolnation' 'raining' 'comes' 'oohooh' 'fm' 'ground' 'gun'\n",
      " 'hey']\n"
     ]
    }
   ],
   "source": [
    "tfidf_rock = get_tfidf(corpus_rock, 1.0, 0.0)\n",
    "print(\"Features with lowest tfidf:\\n{}\".format(tfidf_rock[:10]))\n",
    "\n",
    "print(\"\\nFeatures with highest tfidf: \\n{}\".format(tfidf_rock[-10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUSE\n",
    "- Supervised: using a train bilingual dictionary (or identical character strings as anchor points), learn a mapping from the source to the target space using (iterative) Procrustes alignment.\n",
    "- Unsupervised: without any parallel data or anchor point, learn a mapping from the source to the target space using adversarial training and (iterative) Procrustes refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCH = 5\n",
    "BATCH_SIZE = 32\n",
    "N_ITERATION = round(len(voc_rock)/BATCH_SIZE)\n",
    "REFINEMENT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impossible to import Faiss-GPU. Switching to FAISS-CPU, this will be slower.\n",
      "\n",
      "INFO - 11/28/18 17:40:46 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 11/28/18 17:40:46 - 0:00:00 - adversarial: True\n",
      "                                     batch_size: 32\n",
      "                                     cuda: False\n",
      "                                     dico_build: S2T\n",
      "                                     dico_eval: default\n",
      "                                     dico_max_rank: 15000\n",
      "                                     dico_max_size: 0\n",
      "                                     dico_method: csls_knn_10\n",
      "                                     dico_min_size: 0\n",
      "                                     dico_threshold: 0\n",
      "                                     dis_clip_weights: 0\n",
      "                                     dis_dropout: 0.0\n",
      "                                     dis_hid_dim: 2048\n",
      "                                     dis_input_dropout: 0.1\n",
      "                                     dis_lambda: 1\n",
      "                                     dis_layers: 2\n",
      "                                     dis_most_frequent: 500\n",
      "                                     dis_optimizer: sgd,lr=0.1\n",
      "                                     dis_smooth: 0.1\n",
      "                                     dis_steps: 5\n",
      "                                     emb_dim: 100\n",
      "                                     epoch_size: 1062\n",
      "                                     exp_id: \n",
      "                                     exp_name: debug\n",
      "                                     exp_path: /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy\n",
      "                                     export: txt\n",
      "                                     lr_decay: 0.98\n",
      "                                     lr_shrink: 0.5\n",
      "                                     map_beta: 0.001\n",
      "                                     map_id_init: True\n",
      "                                     map_optimizer: sgd,lr=0.1\n",
      "                                     max_vocab: 200000\n",
      "                                     min_lr: 1e-06\n",
      "                                     n_epochs: 5\n",
      "                                     n_refinement: 5\n",
      "                                     normalize_embeddings: \n",
      "                                     seed: -1\n",
      "                                     src_emb: model_lyrics_rock.vec\n",
      "                                     src_lang: rock\n",
      "                                     tgt_emb: model_lyrics_pop.vec\n",
      "                                     tgt_lang: pop\n",
      "                                     verbose: 2\n",
      "INFO - 11/28/18 17:40:46 - 0:00:00 - The experiment will be stored in /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy\n",
      "INFO - 11/28/18 17:40:47 - 0:00:01 - Loaded 33997 pre-trained word embeddings.\n",
      "INFO - 11/28/18 17:40:49 - 0:00:03 - Loaded 29549 pre-trained word embeddings.\n",
      "INFO - 11/28/18 17:40:49 - 0:00:03 - ----> ADVERSARIAL TRAINING <----\n",
      "                                     \n",
      "                                     \n",
      "INFO - 11/28/18 17:40:49 - 0:00:03 - Starting adversarial training epoch 0...\n",
      "INFO - 11/28/18 17:40:49 - 0:00:04 - 000000 - Discriminator loss: 0.5532 - 185 samples/s\n",
      "INFO - 11/28/18 17:41:12 - 0:00:26 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:41:12 - 0:00:26 - New train dictionary of 4528 pairs.\n",
      "INFO - 11/28/18 17:41:12 - 0:00:26 - Mean cosine (nn method, S2T build, 10000 max size): 0.45667\n",
      "INFO - 11/28/18 17:41:53 - 0:01:07 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:41:53 - 0:01:07 - New train dictionary of 4628 pairs.\n",
      "INFO - 11/28/18 17:41:53 - 0:01:07 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.44126\n",
      "INFO - 11/28/18 17:41:53 - 0:01:07 - __log__:{\"n_epoch\": 0, \"mean_cosine-nn-S2T-10000\": 0.45666904374628, \"mean_cosine-csls_knn_10-S2T-10000\": 0.44126164409281265}\n",
      "INFO - 11/28/18 17:41:53 - 0:01:07 - * Best value for \"mean_cosine-csls_knn_10-S2T-10000\": 0.44126\n",
      "INFO - 11/28/18 17:41:53 - 0:01:07 - * Saving the mapping to /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy/best_mapping.pth ...\n",
      "INFO - 11/28/18 17:41:53 - 0:01:07 - End of epoch 0.\n",
      "                                     \n",
      "                                     \n",
      "INFO - 11/28/18 17:41:53 - 0:01:07 - Decreasing learning rate: 0.10000000 -> 0.09800000\n",
      "INFO - 11/28/18 17:41:53 - 0:01:07 - Starting adversarial training epoch 1...\n",
      "INFO - 11/28/18 17:41:53 - 0:01:08 - 000000 - Discriminator loss: 0.4896 - 211 samples/s\n",
      "INFO - 11/28/18 17:42:16 - 0:01:30 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:42:16 - 0:01:30 - New train dictionary of 4685 pairs.\n",
      "INFO - 11/28/18 17:42:16 - 0:01:30 - Mean cosine (nn method, S2T build, 10000 max size): 0.50835\n",
      "INFO - 11/28/18 17:42:56 - 0:02:11 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:42:56 - 0:02:11 - New train dictionary of 4658 pairs.\n",
      "INFO - 11/28/18 17:42:56 - 0:02:11 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.48409\n",
      "INFO - 11/28/18 17:42:56 - 0:02:11 - __log__:{\"n_epoch\": 1, \"mean_cosine-nn-S2T-10000\": 0.5083476452333823, \"mean_cosine-csls_knn_10-S2T-10000\": 0.48408534617741866}\n",
      "INFO - 11/28/18 17:42:56 - 0:02:11 - * Best value for \"mean_cosine-csls_knn_10-S2T-10000\": 0.48409\n",
      "INFO - 11/28/18 17:42:56 - 0:02:11 - * Saving the mapping to /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy/best_mapping.pth ...\n",
      "INFO - 11/28/18 17:42:56 - 0:02:11 - End of epoch 1.\n",
      "                                     \n",
      "                                     \n",
      "INFO - 11/28/18 17:42:56 - 0:02:11 - Decreasing learning rate: 0.09800000 -> 0.09604000\n",
      "INFO - 11/28/18 17:42:56 - 0:02:11 - Starting adversarial training epoch 2...\n",
      "INFO - 11/28/18 17:42:56 - 0:02:11 - 000000 - Discriminator loss: 0.4426 - 201 samples/s\n",
      "INFO - 11/28/18 17:43:18 - 0:02:33 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:43:18 - 0:02:33 - New train dictionary of 4701 pairs.\n",
      "INFO - 11/28/18 17:43:18 - 0:02:33 - Mean cosine (nn method, S2T build, 10000 max size): 0.51909\n",
      "INFO - 11/28/18 17:44:00 - 0:03:14 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:44:00 - 0:03:14 - New train dictionary of 4545 pairs.\n",
      "INFO - 11/28/18 17:44:00 - 0:03:14 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.49832\n",
      "INFO - 11/28/18 17:44:00 - 0:03:14 - __log__:{\"n_epoch\": 2, \"mean_cosine-nn-S2T-10000\": 0.5190871642374328, \"mean_cosine-csls_knn_10-S2T-10000\": 0.4983181943364925}\n",
      "INFO - 11/28/18 17:44:00 - 0:03:14 - * Best value for \"mean_cosine-csls_knn_10-S2T-10000\": 0.49832\n",
      "INFO - 11/28/18 17:44:00 - 0:03:14 - * Saving the mapping to /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy/best_mapping.pth ...\n",
      "INFO - 11/28/18 17:44:00 - 0:03:14 - End of epoch 2.\n",
      "                                     \n",
      "                                     \n",
      "INFO - 11/28/18 17:44:00 - 0:03:14 - Decreasing learning rate: 0.09604000 -> 0.09411920\n",
      "INFO - 11/28/18 17:44:00 - 0:03:14 - Starting adversarial training epoch 3...\n",
      "INFO - 11/28/18 17:44:00 - 0:03:14 - 000000 - Discriminator loss: 0.4581 - 210 samples/s\n",
      "INFO - 11/28/18 17:44:22 - 0:03:36 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:44:22 - 0:03:36 - New train dictionary of 4662 pairs.\n",
      "INFO - 11/28/18 17:44:22 - 0:03:36 - Mean cosine (nn method, S2T build, 10000 max size): 0.53302\n",
      "INFO - 11/28/18 17:45:06 - 0:04:21 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:45:06 - 0:04:21 - New train dictionary of 4516 pairs.\n",
      "INFO - 11/28/18 17:45:06 - 0:04:21 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.51074\n",
      "INFO - 11/28/18 17:45:06 - 0:04:21 - __log__:{\"n_epoch\": 3, \"mean_cosine-nn-S2T-10000\": 0.5330162121982648, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5107404756185701}\n",
      "INFO - 11/28/18 17:45:06 - 0:04:21 - * Best value for \"mean_cosine-csls_knn_10-S2T-10000\": 0.51074\n",
      "INFO - 11/28/18 17:45:06 - 0:04:21 - * Saving the mapping to /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy/best_mapping.pth ...\n",
      "INFO - 11/28/18 17:45:06 - 0:04:21 - End of epoch 3.\n",
      "                                     \n",
      "                                     \n",
      "INFO - 11/28/18 17:45:06 - 0:04:21 - Decreasing learning rate: 0.09411920 -> 0.09223682\n",
      "INFO - 11/28/18 17:45:06 - 0:04:21 - Starting adversarial training epoch 4...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 11/28/18 17:45:07 - 0:04:21 - 000000 - Discriminator loss: 0.4655 - 211 samples/s\n",
      "INFO - 11/28/18 17:45:28 - 0:04:42 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:45:28 - 0:04:42 - New train dictionary of 4733 pairs.\n",
      "INFO - 11/28/18 17:45:28 - 0:04:42 - Mean cosine (nn method, S2T build, 10000 max size): 0.54008\n",
      "INFO - 11/28/18 17:46:08 - 0:05:22 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:46:08 - 0:05:22 - New train dictionary of 4451 pairs.\n",
      "INFO - 11/28/18 17:46:08 - 0:05:22 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.51886\n",
      "INFO - 11/28/18 17:46:08 - 0:05:22 - __log__:{\"n_epoch\": 4, \"mean_cosine-nn-S2T-10000\": 0.5400819420348558, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5188626367954479}\n",
      "INFO - 11/28/18 17:46:08 - 0:05:22 - * Best value for \"mean_cosine-csls_knn_10-S2T-10000\": 0.51886\n",
      "INFO - 11/28/18 17:46:08 - 0:05:22 - * Saving the mapping to /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy/best_mapping.pth ...\n",
      "INFO - 11/28/18 17:46:08 - 0:05:22 - End of epoch 4.\n",
      "                                     \n",
      "                                     \n",
      "INFO - 11/28/18 17:46:08 - 0:05:22 - Decreasing learning rate: 0.09223682 -> 0.09039208\n",
      "INFO - 11/28/18 17:46:08 - 0:05:22 - ----> ITERATIVE PROCRUSTES REFINEMENT <----\n",
      "                                     \n",
      "                                     \n",
      "INFO - 11/28/18 17:46:08 - 0:05:22 - * Reloading the best model from /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy/best_mapping.pth ...\n",
      "INFO - 11/28/18 17:46:08 - 0:05:22 - Starting refinement iteration 0...\n",
      "INFO - 11/28/18 17:46:08 - 0:05:22 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:46:34 - 0:05:48 - New train dictionary of 8820 pairs.\n",
      "INFO - 11/28/18 17:46:46 - 0:06:01 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:46:46 - 0:06:01 - New train dictionary of 3848 pairs.\n",
      "INFO - 11/28/18 17:46:46 - 0:06:01 - Mean cosine (nn method, S2T build, 10000 max size): 0.56637\n",
      "INFO - 11/28/18 17:47:29 - 0:06:43 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:47:29 - 0:06:43 - New train dictionary of 4261 pairs.\n",
      "INFO - 11/28/18 17:47:29 - 0:06:43 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.54936\n",
      "INFO - 11/28/18 17:47:29 - 0:06:43 - __log__:{\"n_iter\": 0, \"mean_cosine-nn-S2T-10000\": 0.5663700796230048, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5493603556879639}\n",
      "INFO - 11/28/18 17:47:29 - 0:06:43 - * Best value for \"mean_cosine-csls_knn_10-S2T-10000\": 0.54936\n",
      "INFO - 11/28/18 17:47:29 - 0:06:43 - * Saving the mapping to /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy/best_mapping.pth ...\n",
      "INFO - 11/28/18 17:47:29 - 0:06:43 - End of refinement iteration 0.\n",
      "                                     \n",
      "                                     \n",
      "INFO - 11/28/18 17:47:29 - 0:06:43 - Starting refinement iteration 1...\n",
      "INFO - 11/28/18 17:47:29 - 0:06:44 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:47:57 - 0:07:11 - New train dictionary of 8584 pairs.\n",
      "INFO - 11/28/18 17:48:09 - 0:07:24 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:48:09 - 0:07:24 - New train dictionary of 3829 pairs.\n",
      "INFO - 11/28/18 17:48:09 - 0:07:24 - Mean cosine (nn method, S2T build, 10000 max size): 0.58613\n",
      "INFO - 11/28/18 17:49:00 - 0:08:14 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:49:00 - 0:08:14 - New train dictionary of 4399 pairs.\n",
      "INFO - 11/28/18 17:49:00 - 0:08:14 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.57165\n",
      "INFO - 11/28/18 17:49:00 - 0:08:14 - __log__:{\"n_iter\": 1, \"mean_cosine-nn-S2T-10000\": 0.5861280349643401, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5716453365343055}\n",
      "INFO - 11/28/18 17:49:00 - 0:08:14 - * Best value for \"mean_cosine-csls_knn_10-S2T-10000\": 0.57165\n",
      "INFO - 11/28/18 17:49:00 - 0:08:14 - * Saving the mapping to /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy/best_mapping.pth ...\n",
      "INFO - 11/28/18 17:49:00 - 0:08:14 - End of refinement iteration 1.\n",
      "                                     \n",
      "                                     \n",
      "INFO - 11/28/18 17:49:00 - 0:08:14 - Starting refinement iteration 2...\n",
      "INFO - 11/28/18 17:49:00 - 0:08:14 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:49:28 - 0:08:42 - New train dictionary of 8816 pairs.\n",
      "INFO - 11/28/18 17:49:40 - 0:08:55 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:49:40 - 0:08:55 - New train dictionary of 3822 pairs.\n",
      "INFO - 11/28/18 17:49:40 - 0:08:55 - Mean cosine (nn method, S2T build, 10000 max size): 0.59715\n",
      "INFO - 11/28/18 17:50:23 - 0:09:38 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:50:23 - 0:09:38 - New train dictionary of 4458 pairs.\n",
      "INFO - 11/28/18 17:50:23 - 0:09:38 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.58175\n",
      "INFO - 11/28/18 17:50:23 - 0:09:38 - __log__:{\"n_iter\": 2, \"mean_cosine-nn-S2T-10000\": 0.5971477897940102, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5817521355541472}\n",
      "INFO - 11/28/18 17:50:23 - 0:09:38 - * Best value for \"mean_cosine-csls_knn_10-S2T-10000\": 0.58175\n",
      "INFO - 11/28/18 17:50:23 - 0:09:38 - * Saving the mapping to /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy/best_mapping.pth ...\n",
      "INFO - 11/28/18 17:50:23 - 0:09:38 - End of refinement iteration 2.\n",
      "                                     \n",
      "                                     \n",
      "INFO - 11/28/18 17:50:23 - 0:09:38 - Starting refinement iteration 3...\n",
      "INFO - 11/28/18 17:50:23 - 0:09:38 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:50:49 - 0:10:03 - New train dictionary of 8899 pairs.\n",
      "INFO - 11/28/18 17:51:02 - 0:10:17 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:51:02 - 0:10:17 - New train dictionary of 3890 pairs.\n",
      "INFO - 11/28/18 17:51:02 - 0:10:17 - Mean cosine (nn method, S2T build, 10000 max size): 0.60304\n",
      "INFO - 11/28/18 17:52:11 - 0:11:26 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:52:11 - 0:11:26 - New train dictionary of 4498 pairs.\n",
      "INFO - 11/28/18 17:52:11 - 0:11:26 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.58897\n",
      "INFO - 11/28/18 17:52:11 - 0:11:26 - __log__:{\"n_iter\": 3, \"mean_cosine-nn-S2T-10000\": 0.6030379342695741, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5889726750131924}\n",
      "INFO - 11/28/18 17:52:11 - 0:11:26 - * Best value for \"mean_cosine-csls_knn_10-S2T-10000\": 0.58897\n",
      "INFO - 11/28/18 17:52:11 - 0:11:26 - * Saving the mapping to /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy/best_mapping.pth ...\n",
      "INFO - 11/28/18 17:52:11 - 0:11:26 - End of refinement iteration 3.\n",
      "                                     \n",
      "                                     \n",
      "INFO - 11/28/18 17:52:11 - 0:11:26 - Starting refinement iteration 4...\n",
      "INFO - 11/28/18 17:52:12 - 0:11:26 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:52:42 - 0:11:56 - New train dictionary of 8986 pairs.\n",
      "INFO - 11/28/18 17:52:57 - 0:12:11 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:52:57 - 0:12:11 - New train dictionary of 3920 pairs.\n",
      "INFO - 11/28/18 17:52:57 - 0:12:11 - Mean cosine (nn method, S2T build, 10000 max size): 0.60935\n",
      "INFO - 11/28/18 17:53:46 - 0:13:01 - Building the train dictionary ...\n",
      "INFO - 11/28/18 17:53:46 - 0:13:01 - New train dictionary of 4496 pairs.\n",
      "INFO - 11/28/18 17:53:46 - 0:13:01 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.59523\n",
      "INFO - 11/28/18 17:53:46 - 0:13:01 - __log__:{\"n_iter\": 4, \"mean_cosine-nn-S2T-10000\": 0.6093463230117852, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5952336247877824}\n",
      "INFO - 11/28/18 17:53:46 - 0:13:01 - * Best value for \"mean_cosine-csls_knn_10-S2T-10000\": 0.59523\n",
      "INFO - 11/28/18 17:53:46 - 0:13:01 - * Saving the mapping to /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy/best_mapping.pth ...\n",
      "INFO - 11/28/18 17:53:46 - 0:13:01 - End of refinement iteration 4.\n",
      "                                     \n",
      "                                     \n",
      "INFO - 11/28/18 17:53:46 - 0:13:01 - * Reloading the best model from /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy/best_mapping.pth ...\n",
      "INFO - 11/28/18 17:53:46 - 0:13:01 - Reloading all embeddings for mapping ...\n",
      "INFO - 11/28/18 17:53:48 - 0:13:02 - Loaded 33997 pre-trained word embeddings.\n",
      "INFO - 11/28/18 17:53:49 - 0:13:04 - Loaded 29549 pre-trained word embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 11/28/18 17:53:49 - 0:13:04 - Map source embeddings to the target space ...\n",
      "INFO - 11/28/18 17:53:49 - 0:13:04 - Writing source embeddings to /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy/vectors-rock.txt ...\n",
      "INFO - 11/28/18 17:53:55 - 0:13:10 - Writing target embeddings to /Users/emma/Cours/Sem_3/Lyrix/MUSE/MUSE-master/dumped/debug/va2dinkpoy/vectors-pop.txt ...\n"
     ]
    }
   ],
   "source": [
    "! python MUSE-master/unsupervised.py --src_lang rock --tgt_lang pop --src_emb model_lyrics_rock.vec --tgt_emb model_lyrics_pop.vec --n_epochs $N_EPOCH --epoch_size $N_ITERATION --batch_size $BATCH_SIZE --n_refinement $REFINEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'swollen eyes that bleed for you cold steel bars i m watching thru you ve been baptized in a lake of tears crucified yourself with your own fears but you learn from what s killing you and this time it s real beyond your prayers too numb to feel beyond your prayers deepest darkest thoughts you dream curing s harder than it seems slave to no one but your misery broken man lies where you used to be'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_idx = random.randint(1,len(corpus_rock))\n",
    "input_lyrics = corpus_rock[rand_idx]\n",
    "input_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_tfidf = []\n",
    "idx_of_tfidf = []\n",
    "for w in input_lyrics.split(' '):\n",
    "    idx = np.where(tfidf_rock==w)[0]\n",
    "    if len(idx)!= 0:\n",
    "        words_in_tfidf.append(w)\n",
    "        idx_of_tfidf.append(idx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_terms = np.array(words_in_tfidf)[np.argsort(idx_of_tfidf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS_TO_SWAP = ordered_terms[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['curing', 'swollen', 'fears', 'prayers', 'prayers', 'thoughts',\n",
       "       'darkest', 'baptized', 'lake', 'crucified'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORDS_TO_SWAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "muse_emb_rock = \"vectors-rock.txt\"\n",
    "muse_emb_pop = \"vectors-pop.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "muse_emb_rock, muse_voc_rock = load_embeddings(muse_emb_rock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "muse_emb_pop, muse_voc_pop = load_embeddings(muse_emb_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(embed, voc):\n",
    "    voc_embeds_dict = {}\n",
    "    embeds_voc_dict = {}\n",
    "\n",
    "    for v, emb in zip(voc, embed):\n",
    "        voc_embeds_dict[v] = tuple(emb)\n",
    "        embeds_voc_dict[tuple(emb)] = v\n",
    "    return voc_embeds_dict, embeds_voc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc2embed_rock, embed2voc_rock = get_dict(word_embeddings_rock, vocabulary_rock)\n",
    "voc2embed_pop, embed2voc_pop = get_dict(word_embeddings_pop, vocabulary_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_movement(w):\n",
    "    print(\"Movement in rock : \")\n",
    "    print(sum(np.array(muse_voc2embed_rock[w]) - voc2embed_rock[w]))\n",
    "    print(\"Distance in fastext between 2 words : \")\n",
    "    print(sum(np.array(voc2embed_rock[w])- voc2embed_pop[w]))\n",
    "    print(\"Distance in muse between 2 words : \")\n",
    "    print(sum(np.array(muse_voc2embed_rock[w])- muse_voc2embed_pop[w]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "muse_voc2embed_rock, muse_embed2voc_rock = get_dict(muse_emb_rock, muse_voc_rock) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "muse_voc2embed_pop, muse_embed2voc_pop = get_dict(muse_emb_pop, muse_voc_pop) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movement in rock : \n",
      "8.153664\n",
      "Distance in fastext between 2 words : \n",
      "-11.97545775\n",
      "Distance in muse between 2 words : \n",
      "-6.58084\n"
     ]
    }
   ],
   "source": [
    "see_movement('music')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=3, p=2, radius=1.0)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_pop = NearestNeighbors(n_neighbors=3)\n",
    "neigh_pop.fit(muse_emb_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=3, p=2, radius=1.0)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_rock = NearestNeighbors(n_neighbors=3)\n",
    "neigh_rock.fit(muse_emb_rock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_embed(emd, genre):\n",
    "    if genre == 'pop':\n",
    "        idx = neigh_pop.kneighbors([emb],return_distance=False)\n",
    "        return muse_emb_pop[idx][0]\n",
    "    elif genre == 'rock':\n",
    "        idx = neigh_rock.kneighbors([emb],return_distance=False)\n",
    "        return muse_emb_rock[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curing  -->  ['gossiping', 'f**king', 'hawking']\n",
      "swollen  -->  ['murmuring', 'melbourne', 'whippoorwill']\n",
      "fears  -->  ['sheltering', 'sheltered', 'enlightened']\n",
      "prayers  -->  ['saddens', 'downfalls', 'willyes']\n",
      "prayers  -->  ['saddens', 'downfalls', 'willyes']\n",
      "thoughts  -->  ['imaginings', 'belongings', 'enlightened']\n",
      "darkest  -->  ['meltdown', 'rundown', 'breakthrough']\n",
      "baptized  -->  ['youhung', 'funktafied', 'hellafied']\n",
      "lake  -->  ['sunk', 'roooll', 'floozy']\n",
      "crucified  -->  ['funktafied', 'advertised', 'amplified']\n"
     ]
    }
   ],
   "source": [
    "swap = {}\n",
    "for w in WORDS_TO_SWAP:\n",
    "    #Read original embedding\n",
    "    \"\"\"idx = vocabulary_rock.index(w)\n",
    "    emb = word_embeddings_rock[idx]\n",
    "    print(w, emb)\"\"\"\n",
    "    #Read mapped embedding\n",
    "    emb = muse_voc2embed_rock[w]\n",
    "    nearest_pop_emb = get_nearest_embed(emb, 'pop')\n",
    "    words = []\n",
    "    for i in range(3):\n",
    "        words.append(muse_embed2voc_pop[tuple(list(nearest_pop_emb[i]))])\n",
    "    swap[w] = words\n",
    "    print(w,' --> ',swap[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['murmuring', 'melbourne', 'whippoorwill'],\n",
       " 'eyes',\n",
       " 'that',\n",
       " 'bleed',\n",
       " 'for',\n",
       " 'you',\n",
       " 'cold',\n",
       " 'steel',\n",
       " 'bars',\n",
       " 'i',\n",
       " 'm',\n",
       " 'watching',\n",
       " 'thru',\n",
       " 'you',\n",
       " 've',\n",
       " 'been',\n",
       " ['youhung', 'funktafied', 'hellafied'],\n",
       " 'in',\n",
       " 'a',\n",
       " ['sunk', 'roooll', 'floozy'],\n",
       " 'of',\n",
       " 'tears',\n",
       " ['funktafied', 'advertised', 'amplified'],\n",
       " 'yourself',\n",
       " 'with',\n",
       " 'your',\n",
       " 'own',\n",
       " ['sheltering', 'sheltered', 'enlightened'],\n",
       " 'but',\n",
       " 'you',\n",
       " 'learn',\n",
       " 'from',\n",
       " 'what',\n",
       " 's',\n",
       " 'killing',\n",
       " 'you',\n",
       " 'and',\n",
       " 'this',\n",
       " 'time',\n",
       " 'it',\n",
       " 's',\n",
       " 'real',\n",
       " 'beyond',\n",
       " 'your',\n",
       " ['saddens', 'downfalls', 'willyes'],\n",
       " 'too',\n",
       " 'numb',\n",
       " 'to',\n",
       " 'feel',\n",
       " 'beyond',\n",
       " 'your',\n",
       " ['saddens', 'downfalls', 'willyes'],\n",
       " 'deepest',\n",
       " ['meltdown', 'rundown', 'breakthrough'],\n",
       " ['imaginings', 'belongings', 'enlightened'],\n",
       " 'you',\n",
       " 'dream',\n",
       " ['gossiping', 'f**king', 'hawking'],\n",
       " 's',\n",
       " 'harder',\n",
       " 'than',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'slave',\n",
       " 'to',\n",
       " 'no',\n",
       " 'one',\n",
       " 'but',\n",
       " 'your',\n",
       " 'misery',\n",
       " 'broken',\n",
       " 'man',\n",
       " 'lies',\n",
       " 'where',\n",
       " 'you',\n",
       " 'used',\n",
       " 'to',\n",
       " 'be']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print new lyrics\n",
    "words = input_lyrics.split(' ')\n",
    "for i, w in enumerate(words):\n",
    "    if w in WORDS_TO_SWAP:\n",
    "        words[i] = swap[w]\n",
    "\n",
    "words"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
